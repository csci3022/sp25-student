{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc255dd2-0ee4-4308-b2cc-173178ea709c",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares (OLS)\n",
    "\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/fa23/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None \n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "np.random.seed(42)\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921120d9-7c8c-4dbc-80ee-0f637a5f4578",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ex 1: Predicting MSRP\n",
    "\n",
    "Let's explore the Python syntax for performing ordinary least squares programmatically.\n",
    "\n",
    "Today, we will work a dataset about hybrid cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed1df3-eb02-4e6d-b04e-091493da70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.read_csv('data/hybrid.csv')\n",
    "hybrid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cf5d9",
   "metadata": {},
   "source": [
    "Suppose we want to use this dataset to build a model to predict MSRP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097f3db",
   "metadata": {},
   "source": [
    "Let's start by examining the correlation between MSRP and the other variables in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the pairwise scatterplots\n",
    "sns.pairplot(hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e012b257",
   "metadata": {},
   "source": [
    "## Review:  SLR: Least Squares Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ec389-180e-4fa8-ab2a-86df83514f28",
   "metadata": {},
   "source": [
    "We'll start by constructing a least squares regression model to predict the MSRP from the acceleration. Our model will take the form:\n",
    "\n",
    "$$\\text{MSRP} = \\theta_0 + \\theta_1 \\text{acceleration}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize this data:\n",
    "sns.scatterplot(x=hybrid[\"acceleration\"], y=hybrid[\"msrp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9f612-dab1-4494-a100-eb200f6c91c9",
   "metadata": {},
   "source": [
    "## SLR via `sklearn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787a703-ad56-4ec7-ae1f-01b2989d4355",
   "metadata": {},
   "source": [
    "There are three steps to creating and using a model in `sklearn`. \n",
    "\n",
    "**(1) Initialize an instance of the model class**\n",
    "\n",
    "`sklearn` stores \"templates\" of useful models for machine learning. We begin the modeling process by making a \"copy\" of one of these templates for our own use. Model initialization looks like `ModelClass()`, where `ModelClass` is the type of model we wish to create.\n",
    "\n",
    "For now, let's create a linear regression model using `LinearRegression()`. \n",
    "\n",
    "`my_model` is now an instance of the `LinearRegression` class. You can think of it as the \"idea\" of a linear regression model. We haven't trained it yet, so it doesn't know any model parameters and cannot be used to make predictions. In fact, we haven't even told it what data to use for modeling! It simply waits for further instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ebdf4-c362-4e8f-9ace-7c58959b1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "my_model = lm.LinearRegression()\n",
    "\n",
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e28647-a19a-46e2-9704-64a89b4c53e9",
   "metadata": {},
   "source": [
    "**(2) Train the model using `.fit`**\n",
    "\n",
    "Before the model can make predictions, we will need to fit it to our training data. When we fit the model, `sklearn` will run gradient descent behind the scenes to determine the optimal model parameters. It will then save these model parameters to our model instance for future use. \n",
    "\n",
    "All `sklearn` model classes include a `.fit` method. This function is used to fit the model. It takes in two inputs: the design matrix, `X`, and the target variable, `y`. \n",
    "\n",
    "Let's start by fitting a model with just one feature: the acceleration. We create a design matrix `X` by pulling out the `\"acceleration\"` column from the DataFrame. Notice that we use **double brackets** to extract this column. Why double brackets instead of just single brackets? The `.fit` method, by default, expects to receive **2-dimensional** data â€“ some kind of data that includes both rows and columns. Writing `hybrid[\"acceleration\"]` would return a 1D `Series`, causing `sklearn` to error. We avoid this by writing `hybrid[[\"acceleration\"]]` to produce a 2D DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bbfd8-08c1-400d-8be7-d1024f7164f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .fit expects a 2D data design matrix, so we use double brackets to extract a DataFrame\n",
    "X = hybrid[[\"acceleration\"]]\n",
    "y = hybrid[\"msrp\"]\n",
    "\n",
    "my_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510bea9-15ba-49a8-adb0-fcca38c2f648",
   "metadata": {},
   "source": [
    "And in just three lines of code, our model has determined the optimal model parameters! Our single-feature model takes the form:\n",
    "\n",
    "$$\\text{MSRP} = \\theta_0 + \\theta_1 \\text{acceleration}$$\n",
    "\n",
    "Note that `LinearRegression` will automatically include an intercept term. (If you **don't** want to include an intercept you should use `lm.LinearRegression(fit_intercept=False)`)\n",
    "\n",
    "The fitted model parameters are stored as attributes of the model instance. `my_model.intercept_` will return the value of $\\hat{\\theta}_0$ as a scalar. `my_model.coef_` will return all values $\\hat{\\theta}_1, \n",
    "\\hat{\\theta}_1, ...$ in an array. Because our model only contains one feature, we see just the value of $\\hat{\\theta}_1$ in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63252e1e-02ef-40de-ae52-c373c98e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The intercept term, theta_0\n",
    "my_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bba83-0da2-4db7-9f1d-9664bff520d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parameters theta_1, ..., theta_p\n",
    "my_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50585c38-4a63-4864-bb67-c0a5562e60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model:\n",
    "print (\"SLR Model: MSRP =\", round(my_model.intercept_, 0), \"+\", round(my_model.coef_[0], 0),\"acceleration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a2c68-4bc5-42e3-b1ca-529323b79014",
   "metadata": {},
   "source": [
    "**(3) Use the fitted model to make predictions**\n",
    "\n",
    "Now that the model has been trained, we can use it to make predictions! To do so, we use the `.predict` method. `.predict` takes in one argument, the design matrix that should be used to generate predictions. To understand how the model performs on the training set, we would pass in the training data. Alternatively, to make predictions on unseen data, we would pass in a new dataset that wasn't used to train the model.\n",
    "\n",
    "Below, we call `.predict` to generate model predictions on the original training data. As before, we use double brackets to ensure that we extract 2-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f8b82-de61-485e-b374-8a8ccfbfa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = my_model.predict(hybrid[[\"acceleration\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fec7c6-069e-40d6-bb9e-208a44f209fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predict([[13]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707dbbe-e7bd-45de-81f8-cac974bfb41f",
   "metadata": {},
   "source": [
    "### Analyze Model Fit\n",
    "\n",
    "#### RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397c700-de36-47b9-a0d2-192c061466cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The RMSE of the SLR model is {np.sqrt(np.mean((y-y_hat)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3fb88-c4ec-4560-ae21-0501ff67ed4b",
   "metadata": {},
   "source": [
    "#### $r^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30e180-4210-467b-b580-46cb27c6e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284b739-36b1-4c3d-bd69-40eb2e611d6c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Visualizing Model and Residuals\n",
    "\n",
    "\n",
    "Next, we **plot the residuals.** \n",
    "\n",
    "When we make a residual plot, we'll put the residuals on the y-axis.  But we have an option of what to use for the x-axis:  either the single input feature (in this case `acceleration` OR the fitted y-values (i.e. the predicted y output of the model).  When we have more than one feature i.e. in Multiple Linear Regression, we usually just plot the residuals vs the fitted y-values.  \n",
    "\n",
    "\n",
    "For reference we'll provide both residual plots below.  We also replot the original dataset and our SLR model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f2f20-3a62-42e3-ad22-98d9e751c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_msrp = y_hat\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "\n",
    "ax[0].scatter(hybrid[\"acceleration\"], hybrid[\"msrp\"])\n",
    "ax[0].plot(hybrid[\"acceleration\"], predicted_msrp, 'r--')\n",
    "ax[0].set_xlabel('acc')\n",
    "ax[0].set_ylabel('msrp')\n",
    "ax[0].set_title('SLR')\n",
    "\n",
    "\n",
    "\n",
    "ax[1].scatter(hybrid[\"acceleration\"], hybrid[\"msrp\"] - predicted_msrp)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'acc')\n",
    "ax[1].set_ylabel(r'Residuals: $y - \\hat{y}$');\n",
    "ax[1].set_title(\"Residuals vs. acc\")\n",
    "\n",
    "ax[2].scatter(predicted_msrp, hybrid[\"msrp\"] - predicted_msrp)\n",
    "ax[2].axhline(0, c='black', linewidth=1)\n",
    "ax[2].set_xlabel(r'Fitted Values $\\hat{y}$')\n",
    "ax[2].set_ylabel(r'Residuals: $y - \\hat{y}$');\n",
    "ax[2].set_title(\"Residuals vs. predicted msrp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bb8ad",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression:  Adding More Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e064ed",
   "metadata": {},
   "source": [
    "What if we wanted to add more features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5b45f",
   "metadata": {},
   "source": [
    "A quick way to visualize how your dependent variable varies with the other variables in your dataset is to do a pairwise correlation plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fe864-be58-4a6f-991a-fc9b7b49a570",
   "metadata": {},
   "source": [
    "What if we wanted a model with two features? \n",
    "\n",
    "$$\\text{MSRP} = \\theta_0 + \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf29bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(\n",
    "    hybrid, \n",
    "    x=\"mpg\", y=\"acceleration\", z=\"msrp\",\n",
    "    hover_name=\"vehicle\", \n",
    "    color=\"class\", \n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaffb6",
   "metadata": {},
   "source": [
    "We repeat this three-step process by intializing a new model object, then calling `.fit` and `.predict` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0db54-8452-43b5-8b32-73c1416660a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initialize LinearRegression model\n",
    "two_feature_model = lm.LinearRegression()\n",
    "\n",
    "# Step 2: fit the model\n",
    "X_two_features = hybrid[[\"acceleration\", \"mpg\"]]\n",
    "y = hybrid[\"msrp\"]\n",
    "\n",
    "two_feature_model.fit(X_two_features, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_feature_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e13c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_feature_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: make predictions\n",
    "y_hat_two_features = two_feature_model.predict(X_two_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9c9ea-a346-4a63-87c1-b5c5b45614f3",
   "metadata": {},
   "source": [
    "### Visualize Model in 3D (only possible when using 2 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d3e43-e28a-4871-b905-489b12a6f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=two_feature_model.coef_[0]\n",
    "b=two_feature_model.coef_[1]\n",
    "c=two_feature_model.intercept_\n",
    "\n",
    "mpg_range = np.arange(10, 80)\n",
    "acceleration_range = np.arange(5, 25)\n",
    "predictions = pd.DataFrame(columns = [\"mpg\", \"acc\", \"pred\"])\n",
    "for mpg in mpg_range:\n",
    "    for acc in acceleration_range: \n",
    "        pred = a * acc + b * mpg + c\n",
    "        predictions.loc[len(predictions.index)]=[mpg, acc, pred]\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    hybrid, \n",
    "    x=\"mpg\", y=\"acceleration\", z=\"msrp\",\n",
    "    hover_name=\"vehicle\", \n",
    "    color=\"class\", \n",
    "    height=800\n",
    ")\n",
    "fig.add_surface(\n",
    "    x = mpg_range, y = acceleration_range,\n",
    "    z = np.array(predictions[\"pred\"]).reshape(len(mpg_range), len(acceleration_range)).T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0161a-6f7c-45ca-94b7-90f423102cab",
   "metadata": {},
   "source": [
    "### RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d19b6-b72b-45a5-aa9a-a0e0cef09ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The RMSE of the model is {np.sqrt(np.mean((y-y_hat_two_features)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1003b-3389-4661-9904-ab6d2ef05704",
   "metadata": {},
   "source": [
    "### Multiple $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca3308-81fc-4beb-8377-e5ed6a93e5f3",
   "metadata": {},
   "source": [
    "Let's compute the coefficient of determination, or **multiple $R^2$**, for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e160b-d47d-4667-be97-44d55cad68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.var(two_feature_model.predict(X_two_features)) / np.var(hybrid[\"msrp\"])\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3d96a-40fb-49ed-b8ae-31cc78b62aca",
   "metadata": {},
   "source": [
    "There's a built-in method to calculate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6acba-6de0-4847-b269-7dbb3f406177",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_feature_model.score(X_two_features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d0e8d-26a9-4c85-9aab-e34997f3dad6",
   "metadata": {},
   "source": [
    "### Adjusted Multiple R^2\n",
    "\n",
    "Since Multiple R2 always increases as you add more predictors to a model, adjusted R2 can serve as a metric that tells you how useful a model is, adjusted for the number of predictors in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebef56-b811-4d28-a27e-75271c8617ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted Multiple R2\n",
    "1 - (1-two_feature_model.score(X_two_features, y))*(len(y)-1)/(len(y)-X_two_features.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657d5d7-a2fd-4d92-a004-5d82baf4270a",
   "metadata": {},
   "source": [
    "Notice that this is better (i.e. closer to 1) than the r^2 for our SLR model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd92678-533d-4290-baf3-e72cc6be7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b2be3",
   "metadata": {},
   "source": [
    "### Analyze Residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(two_feature_model.predict(X_two_features), hybrid[\"msrp\"] - two_feature_model.predict(X_two_features))\n",
    "plt.axhline(0, c='black', linewidth=1)\n",
    "plt.xlabel(r'Fitted Values $\\hat{y}$')\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title (\"residuals vs predicted msrp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f4d08",
   "metadata": {},
   "source": [
    "## Feature Engineering: \n",
    "\n",
    "\n",
    "Next we will explore a key part of data science, **feature engineering**: _the process of transforming the representation of model inputs to enable better model approximation._  Feature engineering enables you to:\n",
    "\n",
    "1. **encode** non-numeric features to be used as inputs to common numeric models\n",
    "1. capture **domain knowledge** (e.g., the perceived loudness or sound is the log of the intensity)\n",
    "1. **transform** complex relationships into simple linear relationships\n",
    "\n",
    "\n",
    "\n",
    "### Fitting Non-linear Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0ddf1-53f6-41fc-a37f-84c83cbf28c9",
   "metadata": {},
   "source": [
    "We could try to improve our predictions by defining a more complex equation:\n",
    "\n",
    "$$\\text{MSRP} = \\theta_0 + \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4\\sqrt{mpg}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7e10a",
   "metadata": {},
   "source": [
    "We repeat this three-step process by intializing a new model object, then calling `.fit` and `.predict` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7772a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid[\"acc_sq\"] = hybrid[\"acceleration\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid[\"mpg_sqrt\"] = np.sqrt(hybrid[\"mpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initialize LinearRegression model\n",
    "four_feature_model = lm.LinearRegression()\n",
    "\n",
    "# Step 2: fit the model\n",
    "X_four_features = hybrid[[\"acceleration\",\"mpg\",\"acc_sq\",\"mpg_sqrt\"]]\n",
    "y = hybrid[\"msrp\"]\n",
    "\n",
    "four_feature_model.fit(X_four_features, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_feature_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_feature_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb824cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: make predictions\n",
    "y_hat_four_features = four_feature_model.predict(X_four_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd8465-9ca7-4ca1-a117-724c2a59b16a",
   "metadata": {},
   "source": [
    "$$\\text{MSRP} = 263351 -4986( \\text{acc})+ 5045 (\\text{mpg})+ 342({acc})^2 + -67250\\sqrt{mpg}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9261e-a776-4e11-9675-fa67fad455e6",
   "metadata": {},
   "source": [
    "### RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dff073-e4ad-4f79-b5ea-16642a0fb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The RMSE of the model is {np.sqrt(np.mean((y-y_hat_four_features)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5413991-c9ce-4350-96ab-2b1c72d4abde",
   "metadata": {},
   "source": [
    "### Adjusted Multiple $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45c98f-0c4f-4275-b6b2-1b2e73e5b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (1-four_feature_model.score(X_four_features, y))*(len(y)-1)/(len(y)-X_four_features.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b1bb9-38fb-4a51-9c48-9063ddcd8b68",
   "metadata": {},
   "source": [
    "### Analyze Residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze Residuals:\n",
    "\n",
    "plt.scatter(y_hat_four_features, y-y_hat_four_features)\n",
    "plt.axhline(0, c='black', linewidth=1)\n",
    "plt.xlabel(\"predicted msrp\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"Residuals for Model with 4 features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Residuals from our 3 models:\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "\n",
    "\n",
    "ax[0].scatter(predicted_msrp, hybrid[\"msrp\"] - predicted_msrp)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Fitted Values $\\hat{y}$')\n",
    "ax[0].set_ylabel(r'Residuals: $y - \\hat{y}$');\n",
    "ax[0].set_title(\"Residuals for single feature model\")\n",
    "ax[0].set_xlim(9000,101000)\n",
    "\n",
    "\n",
    "ax[1].scatter(two_feature_model.predict(X_two_features), hybrid[\"msrp\"] - two_feature_model.predict(X_two_features))\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Fitted Values $\\hat{y}$')\n",
    "ax[1].set_ylabel(r'Residuals: $y - \\hat{y}$');\n",
    "ax[1].set_title(\"Residuals for 2 feature model\")\n",
    "ax[1].set_xlim(9000,101000)\n",
    "\n",
    "\n",
    "\n",
    "ax[2].scatter(y_hat_four_features, hybrid[\"msrp\"] - y_hat_four_features)\n",
    "ax[2].axhline(0, c='black', linewidth=1)\n",
    "ax[2].set_xlabel(r'Fitted Values $\\hat{y}$')\n",
    "ax[2].set_ylabel(r'Residuals: $y - \\hat{y}$');\n",
    "ax[2].set_title(\"Residuals for 4 feature model\")\n",
    "ax[2].set_xlim(9000,101000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024acac-4b52-4ea4-bb90-653d7313d62b",
   "metadata": {},
   "source": [
    "## Visualization of 4 feature model (acc, mpg, acc^2 and mpg^2) (Only possible because we are using 2 features and their transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5462c05-2189-4392-bc37-84bba35cf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=four_feature_model.coef_[0]\n",
    "b=four_feature_model.coef_[1]\n",
    "c=four_feature_model.coef_[2]\n",
    "d=four_feature_model.coef_[3]\n",
    "e=four_feature_model.intercept_\n",
    "\n",
    "\n",
    "mpg_range = np.arange(10, 80)\n",
    "acceleration_range = np.arange(5, 25)\n",
    "predictions=pd.DataFrame(columns =[\"mpg\", \"acc\", \"pred\"])\n",
    "for mpg in mpg_range:\n",
    "    for acc in acceleration_range: \n",
    "        pred = a*acc + b*mpg + c*acc**2 + d*np.sqrt(mpg) + e\n",
    "        predictions.loc[len(predictions.index)]=[mpg, acc, pred]\n",
    "        \n",
    "fig = px.scatter_3d(\n",
    "    hybrid, \n",
    "    x=\"mpg\", y=\"acceleration\", z=\"msrp\",\n",
    "    hover_name=\"vehicle\", \n",
    "    color=\"class\", \n",
    "    height=800\n",
    ")\n",
    "fig.add_surface(\n",
    "    x = mpg_range, y = acceleration_range,\n",
    "    z = np.array(predictions[\"pred\"]).reshape(len(mpg_range), len(acceleration_range)).T,\n",
    "    showscale=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e702c-e3bc-4dfa-a75c-5d4de864a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce87b4-1f00-4eb5-99d5-4c3bdf84a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[1].scatter(two_feature_model.predict(X_two_features), hybrid[\"msrp\"] - two_feature_model.predict(X_two_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b90e7-7d7e-4630-860b-76dc22ae5644",
   "metadata": {},
   "source": [
    "## More Feature Engineering:  \n",
    "\n",
    "### Adding Qualitative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5bd1b-f709-45fe-b497-04423e98fcc2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "What about qualitative features?  There isn't a way to calculate a \"correlation\" between msrp and class. \n",
    "\n",
    "To see if additional qualitative variables might be helpful, we can plot the residuals from the fitted model against a variable that is not in the model. If we see patterns, that indicates we might want to include this additional feature or a transformation of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ae635-1afd-4ba1-a6ec-78d9108be938",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "m4_error = hybrid[\"msrp\"] - y_hat_four_features\n",
    "\n",
    "\n",
    "hybrid= hybrid.assign(m4_errors=m4_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2d251-8ef6-436e-9889-0d5a1e53b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe8348-8b11-41ef-bc2e-788ba5f3869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(hybrid, x='class', y='m4_errors')\n",
    "\n",
    "fig.add_hline(0, line_width=2, line_dash='dash', opacity=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648498f2-2a92-4139-b35d-fb875bf314b6",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig=px.box(hybrid, x='class', y='m4_errors')\n",
    "\n",
    "fig.add_hline(0, line_width=2, line_dash='dash', opacity=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a745e1-8fec-435a-be7c-e4a4b95790b4",
   "metadata": {},
   "source": [
    "This plot shows us that the distribution of errors appears shifted by car class type. Ideally, the median of each class's box plot lines up with 0 on the y-axis (meaning there was no difference in prediction by city). Instead, we see some variation (especially with Minivans, Pickup Trucks and Large vehicles).  From a context point of view, it makes sense for car type to impact sale price. In the next section, we show how to incorporate a nominal variable into a linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c87537-33bc-48b7-8d6f-2f6d28491d26",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "\n",
    "One-Hot encoding, sometimes also called **dummy encoding** is a simple mechanism to encode categorical data as real numbers such that the magnitude of each dimension is meaningful.  Suppose a feature can take on $k$ distinct values (e.g., $k=50$ for 50 states in the United Stated).  For each distinct _possible_ value a new feature (dimension) is created.  For each record, all the new features are set to zero except the one corresponding to the value in the original feature. \n",
    "\n",
    "The term one-hot encoding comes from a digital circuit encoding of a categorical state as particular \"hot\" wire.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For example, we can use one-hot encoding to incorporate the car's class as an input into a regression model.\n",
    "\n",
    "Suppose we want to add `class` to our model above to predict MSRP.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfe368-2511-40e4-bcb2-f4b73c0a5907",
   "metadata": {},
   "source": [
    "Because `class` is non-numeric, we will apply one-hot encoding before fitting a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba90e0-9a4b-4aa0-8cfd-988f0b800e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid[[\"class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113efbab-eb61-4a35-8709-29ccfcf7004e",
   "metadata": {},
   "source": [
    "## One-Hot Encoding in Scikit-Learn\n",
    "\n",
    "The `OneHotEncoder` class of `sklearn` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.get_feature_names_out)) offers a quick way to perform one-hot encoding. For now, recognize that we follow a very similar workflow to when we were working with the `LinearRegression` class: we initialize a `OneHotEncoder` object, fit it to our data, then use `.transform` to apply the fitted encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497489b-2bd2-4613-a276-924954deeec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abb262-6ca6-4ec7-9b99-21caa36867bc",
   "metadata": {},
   "source": [
    "To \"learn\" the categories we fit the OneHotEncoder to the categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f69a5f-926a-4833-98e8-3e9bd48e72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit(hybrid[[\"class\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffa7d8-fc28-4e8c-9ff4-b56bb3b5d69f",
   "metadata": {},
   "source": [
    "We can get the \"names\" of the new one-hot-encoding columns which reveal both the source columns and the categories within each column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47581afa-f903-4a12-8db5-acb9301a90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1dd2df-800b-4284-83af-1b987a0e0fa4",
   "metadata": {},
   "source": [
    "We can also construct the OneHotEncoding of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efd16b-5758-41d0-a0ca-df0a833d96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(hybrid[[\"class\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fb1f2-7636-435d-bdcd-e44c0196c5f6",
   "metadata": {},
   "source": [
    "Notice that the One-Hot-Encoding produces a sparse output matrix.  This is because most the entries are 0.  If we want to convert this to a numpy matrix that we can see we can use the following syntax:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf46055-cc5a-49f5-82d9-0c1faa7a83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_class = ohe.transform(hybrid[[\"class\"]]).todense()\n",
    "\n",
    "encoded_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87804c-91ab-4aed-969f-139377d5fecb",
   "metadata": {},
   "source": [
    "We can then convert this to a DataFrame (to merge with our feature DataFrame) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6d8e6-3c43-4d00-9364-99484d0fae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_class_df = pd.DataFrame(encoded_class, columns=ohe.get_feature_names_out(), index = hybrid.index)\n",
    "\n",
    "encoded_class_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bb269-c2a8-40fb-b176-8712267b4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid[[\"class\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f967566-07de-44fc-a1d6-af5ace395aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same steps as above, just all in one cell:\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize a OneHotEncoder object\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder\n",
    "ohe.fit(hybrid[[\"class\"]])\n",
    "\n",
    "# Use the encoder to transform the raw \"class feature\n",
    "encoded_class = ohe.transform(hybrid[[\"class\"]]).todense()\n",
    "encoded_class_df = pd.DataFrame(encoded_class, columns=ohe.get_feature_names_out(), index = hybrid.index)\n",
    "\n",
    "encoded_class_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aae640-5c88-4a33-82c8-74c3367a3bf6",
   "metadata": {},
   "source": [
    "### Applying to new data\n",
    "\n",
    "When run on new data with unseen categories the default behavior of the OneHotEncoder is to raise an error but you can also tell it to ignore these categories:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ec919-a528-4e11-83a2-49cfeff3261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ohe.transform(np.array([[\"Compact\"], [\"Two Seater\"], [\"NewType\"]])).todense()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbabb0-fea2-4bb6-9577-aa8f71b14776",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.handle_unknown = 'ignore'\n",
    "ohe.transform(np.array([[\"Compact\"], [\"Two Seater\"], [\"NewType\"]])).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827537e-59ec-44d3-bc0d-d770a4c6a433",
   "metadata": {},
   "source": [
    "### Adding Encoded Data to Design Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556754a1-e4c2-42fb-8da2-b4181e8fd5c1",
   "metadata": {},
   "source": [
    "The `OneHotEncoder` has converted the categorical `class` feature into seven numeric features! \n",
    "\n",
    "Let's join this one-hot encoding to the original data to form our featurized design matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea867e6b-742a-4627-95a2-f0f80d1a0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5_features = X_four_features.copy()\n",
    "X_5_features = X_5_features.join(encoded_class_df)\n",
    "X_5_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302af61-4ba5-42c3-8b53-d2754c46204c",
   "metadata": {},
   "source": [
    "Now, we can use `sklearn`'s `LinearRegression` class to fit a model to this design matrix.\n",
    "\n",
    "\n",
    "We're fitting a model of this form:\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg}+ \\theta_5(classCompact)+\\theta_6(classLarge)+\\theta_7(classMidsize)...$$\n",
    "\n",
    "$$ + \\theta_8(classMinivan)+\\theta_9(classPickupTruck)+\\theta_{10}(classSUV)+\\theta_{11}(classTwoSeater)$$\n",
    "\n",
    "\n",
    "\n",
    "Notice, this is equivalent to fitting 7 models with of this format\n",
    "\n",
    "\n",
    "$$\\text{MSRP} = \\theta_0 + \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg}$$\n",
    "\n",
    "\n",
    "but the intercept term depending on car type:\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg}+ \\theta_5    \\textbf{            (for Compact cars)}$$\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg} + \\theta_6    \\textbf{            (for Large cars)}$$\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg} + \\theta_7    \\textbf{            (for Midsize cars)}$$\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg}+ \\theta_8    \\textbf{            (for Minivans)}$$\n",
    "\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg} + \\theta_9    \\textbf{            (for Pick Up Trucks)}$$\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg} + \\theta_{10}    \\textbf{            (for SUVs)}$$\n",
    "\n",
    "$$\\text{MSRP} = \\theta_1 \\text{acceleration}+ \\theta_2 \\text{mpg}+ \\theta_3({acceleration})^2 + \\theta_4 \\sqrt{mpg} + \\theta_{11}    \\textbf{            (for Two Seaters)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bcc7e-642b-4cf7-bb7b-5d74adc24f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_model = lm.LinearRegression(fit_intercept=False) \n",
    "\n",
    "#Since we are using one-hot encoding, tell sklearn to not add an additional intercept column. \n",
    "\n",
    "ohe_model.fit(X_5_features, y)\n",
    "\n",
    "pd.DataFrame({\"Feature\":X_5_features.columns, \"Model Coefficient\":ohe_model.coef_}).set_index(\"Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7b47c-849c-4733-879f-d3190ea69d34",
   "metadata": {},
   "source": [
    "### RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be6100-1b63-48fd-8747-100ac6f9f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_5_features = ohe_model.predict(X_5_features)\n",
    "\n",
    "print(f\"The RMSE of the model is {np.sqrt(np.mean((y-y_hat_5_features)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55509b4-ee77-49ab-a55f-989de46d571d",
   "metadata": {},
   "source": [
    "### Adjusted Multiple $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e294f-3e21-47c9-8a1e-b67caa33d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (1-ohe_model.score(X_5_features, y))*(len(y)-1)/(len(y)-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefe918-2cb8-4253-8101-098d0c119dac",
   "metadata": {},
   "source": [
    "### Analyze Residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b07ef-a3fa-4674-9af2-e36c34300b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze Residuals:\n",
    "\n",
    "plt.scatter(y_hat_5_features, y-y_hat_5_features)\n",
    "plt.axhline(0, c='black', linewidth=1)\n",
    "plt.xlabel(\"predicted msrp\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"Residuals for Model with 5 features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480b9c9-7bd6-4da0-bc5d-3bfe85785314",
   "metadata": {},
   "source": [
    "## Appendix (Not in Scope): Dealing With _Text_ Features\n",
    "\n",
    "Encoding text as a real-valued feature is especially challenging and many of the standard transformations are **lowsy**. Moreover, all of the earlier transformations (e.g., one-hot encoding and Boolean representations) preserve the information in the feature. In contrast, most of the techniques for encoding text destroy information about the word order and in many cases key parts of the grammar.  \n",
    "\n",
    "Here we present two widely used representations of text:\n",
    "\n",
    "* **Bag-of-Words Encoding**: encodes text by the frequency of each word\n",
    "* **N-Gram Encoding**: encodes text by the frequency of sequences of words of length $N$\n",
    "\n",
    "Both of these encoding strategies are related to the one-hot encoding with dummy features created for every word or sequence of words and with multiple dummy features having counts greater than zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32177db-1481-49b3-b198-ed441cd8f03a",
   "metadata": {},
   "source": [
    "## The Bag-of-Words Encoding\n",
    "\n",
    "\n",
    "The bag-of-words encoding is widely used and a standard representation for text in many of the popular text clustering algorithms.  The following is a simple illustration of the bag-of-words encoding:\n",
    "\n",
    "<img src=\"img/bag_of_words.png\" width=\"600\"> \n",
    "\n",
    "**Notice**\n",
    "1. **Stop words are removed.** Stop-words are words like `is` and `about` that in isolation contain very little information about the meaning of the sentence.  Here is a good list of [stop-words in many languages](https://code.google.com/archive/p/stop-words/). \n",
    "1. **Word order information is lost.**  Nonetheless the vector still suggests that the sentence is about `fun`, `machines`, and `learning`.  Thought there are many possible meanings _learning machines have fun learning_ or _learning about machines is fun learning_ ...\n",
    "1. **Capitalization and punctuation are typically removed.**  \n",
    "1. **Sparse Encoding:** is necessary to represent the bag-of-words efficiently.  There are millions of possible words (including terminology, names, and misspellings) and so instantiating a `0` for every word that is not in each record would be incredibly inefficient.  \n",
    "\n",
    "**Why is it called a bag-of-words?**  A bag is another term for a **multiset**: _an unordered \n",
    "collection which may contain multiple instances of each element._  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ae6d4-6fbf-4a20-b1d5-b1b45a47ab9d",
   "metadata": {},
   "source": [
    "### Implementing the Bag-of-words Model\n",
    "\n",
    "We can use scikit-learn to construct a bag-of-words representation of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd85855-a597-4548-a8f0-790ba9ac09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frost_text = [x for x in \"\"\"\n",
    "Some say the world will end in fire,\n",
    "Some say in ice.\n",
    "From what Ive tasted of desire\n",
    "I hold with those who favor fire.\n",
    "\"\"\".split(\"\\n\") if len(x) > 0]\n",
    "\n",
    "frost_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4ffb6-19d3-453c-a9a3-e40b383ccbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Construct the tokenizer with English stop words\n",
    "bow = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# fit the model to the passage\n",
    "bow.fit(frost_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0474b-e65a-4262-b53b-8f41d923ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the words that are kept\n",
    "print(\"Words:\", list(enumerate(bow.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd062c78-1f48-4f50-b3e7-b44a18477183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentence Encoding: \\n\")\n",
    "# Print the encoding of each line\n",
    "for (s, r) in zip(frost_text, bow.transform(frost_text)):\n",
    "    print(s)\n",
    "    print(r)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c92ca1-e00b-4b92-b934-ee9f03c0aede",
   "metadata": {},
   "source": [
    "## The N-Gram Encoding\n",
    "\n",
    "The N-Gram encoding is a generalization of the bag-of-words encoding designed to capture limited ordering information.  Consider the following passage of text:\n",
    "\n",
    "> _The book was not well written but I did enjoy it._\n",
    "\n",
    "If we re-arrange the words we can also write:\n",
    "\n",
    "> _The book was well written but I did not enjoy it._\n",
    "\n",
    "Moreover, local word order can be important when making decisions about text.  The n-gram encoding captures local word order by defining counts over sliding windows. In the following example a bi-gram ($n=2$) encoding is constructed:\n",
    "\n",
    "<img src=\"img/ngram.png\" width=\"500\"> \n",
    "\n",
    "The above n-gram would be encoded in the sparse vector:\n",
    "\n",
    "<img src=\"img/ngram_vector.png\" width=\"500\"> \n",
    "\n",
    "Notice that the n-gram captures key pieces of sentiment information: `\"well written\"` and `\"not enjoy\"`.  \n",
    "\n",
    "N-grams are often used for other types of sequence data beyond text. For example, n-grams can be used to encode genomic data, protein sequences, and click logs. \n",
    "\n",
    "**N-Gram Issues**\n",
    "1. The n-gram representation is hyper sparse and maintaining the dictionary of possible n-grams can be very costly.  The **hashing trick** is a popular solution to approximate the sparse n-gram encoding.  In the hashing trick each n-gram is mapped to a relatively large (e.g., 32bit) hash-id and the counts are associated with the hash index without saving the n-gram text in a dictionary.  As a consequence, multiple n-grams are treated as the same.\n",
    "1. As $N$ increase the chance of seeing the same n-grams at prediction time decreases rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8bc79-97f6-4982-952e-ec3019a0714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tokenizer with English stop words\n",
    "bigram = CountVectorizer(ngram_range=(1, 2))\n",
    "# fit the model to the passage\n",
    "bigram.fit(frost_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a0c9a-5289-44ad-b0e4-9d78c5359298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the words that are kept\n",
    "print(\"\\nWords:\", \n",
    "      list(zip(range(0,len(bigram.get_feature_names_out())), bigram.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d6e39-dc2f-41c9-aeda-3ab7c93edc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSentence Encoding: \\n\")\n",
    "# Print the encoding of each line\n",
    "for (s, r) in zip(frost_text, bigram.transform(frost_text)):\n",
    "    print(s)\n",
    "    print(r)\n",
    "    print(\"------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
