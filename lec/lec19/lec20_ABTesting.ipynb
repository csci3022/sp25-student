{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Two Samples Using Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing: Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the baby dataset from our lesson on visualization.  In that particular medical study, a sample of newborn babies was obtained from a large hospital system.  We will treat the data as if it were a simple random sample, though the sampling was done in multiple stages. Deborah Nolan and Terry Speed discuss the larger dataset in [Stat Labs](https://www.stat.berkeley.edu/~statlabs/).\n",
    "\n",
    "One of the aims of the study was to see whether maternal smoking was associated with birth weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_df = pd.read_csv(\"data/baby.csv\")\n",
    "\n",
    "births_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of mothers in the study who smoked vs who didn't:\n",
    "\n",
    "(births_df[[\"Maternal Smoker\", \"Birth Weight\"]].groupby(\"Maternal Smoker\")\n",
    "                                                .count()\n",
    "                                                 .rename(columns = {\"Birth Weight\": \"Count\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Two Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(births_df, x=\"Birth Weight\", hue=\"Maternal Smoker\");\n",
    "plt.title(\"Distribution of Birth Weight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(births_df, x = 'Maternal Smoker', y = 'Birth Weight',width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the weights of the babies born to mothers who smoked appears to be shifted slightly lower than the distribution corresponding to non-smoking mothers. The weights of the babies of the mothers who smoked seem lower on average than the weights of the babies of the non-smokers.\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "Similar to the original study, we'd like to study whether this difference reflects just chance variation or perhaps a difference in the distributions in the larger population. Suppose we propose the following two hypotheses:\n",
    "\n",
    "> **Null hypothesis**: In the population, the distribution of birth weights of babies is the same for mothers who don’t smoke as for mothers who do. The (observed) difference in the sample is due to chance.\n",
    "\n",
    "> **Alternative hypothesis**: In the population, the babies of the mothers who smoke have a <i>**lower**</i> birth weight, on average, than the babies of the non-smokers.\n",
    "\n",
    "We would like to perform hypothesis testing using the permutation test. One way to do so is to compute an observed test statistic and then compare it with multiple simulated test statistics, generated through random permutations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Suppose that we choose a reasonable test statistic as the difference between the average birth weights of the two groups (i.e., the **average weights of babies of smokers minus the average weights babies of non-smokers**). \n",
    "\n",
    "What values of our statistic are in favor of the alternative: positive or negative?: **Negative**\n",
    "\n",
    "\n",
    "\n",
    "Fill in the function below to create a function that calculates the difference in means for 2 different categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_means(df, numeric_label, category_label, absol=False):\n",
    "    \"\"\"\n",
    "    Takes: \n",
    "       - name of DataFrame\n",
    "       - column label of numerical variable (i.e. is the weights of the babies)\n",
    "       - column label of boolean variable (i.e. is whether they smoked or not)\n",
    "       \n",
    "    Returns: Difference of means of the two groups\n",
    "    \"\"\"  \n",
    "    #df with the two relevant columns\n",
    "    reduced = df[[numeric_label, category_label]]  \n",
    "    \n",
    "    # df containing group means\n",
    "    means_df = reduced.groupby(category_label).mean().rename(columns = {numeric_label: numeric_label+\" Mean\"})\n",
    "    \n",
    "    #print(means_df)\n",
    "    \n",
    "    if absol==True:\n",
    "        return abs(means_df.iloc[1,0]-means_df.iloc[0,0])\n",
    "    else:\n",
    "        return means_df.loc[True, numeric_label+\" Mean\"] - means_df.loc[False, numeric_label+\" Mean\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, assign `observed_difference` to the **observed test statistic** given our original sample of `nonsmoker_births` and `smoker_births`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_difference = difference_of_means(births_df, 'Birth Weight', 'Maternal Smoker')\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "Before we write any code, let’s explain the idea of hypothesis testing using permutations (shuffling). \n",
    "\n",
    "Hypothesis tests conducted using permutations of data are called permutation tests.   \n",
    " - Our A/B tests are an example of a permutation test\n",
    "\n",
    "To conduct a permutation test, you need two (or more) samples of data, and your null hypothesis is that the samples are random draws from the same underlying distribution.\n",
    "\n",
    "\n",
    "\n",
    "We first simulate the experiment many times (say, 10,000 times) through random permutation (i.e. without replacement). Assuming that the null hypothesis holds, this process will produce an empirical distribution of a predetermined test statistic. Then, we use this empirical distribution to compute an empirical p-value, which is then compared against a particular cutoff threshold in order to accept or reject our null hypothesis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example to show how to conduct random permuations in Python.  We use a toy dataframe of just a few names so it's easier to see how this works before we apply it to our original baby dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy DataFrame to demonstrate how to code permuatations in Python\n",
    "staff = pd.DataFrame(\n",
    "    {       \n",
    "        'Groups': ['Label 1', 'Label 1', 'Label 2', 'Label 2', 'Label 2'],\n",
    "         'Ages': [29, 28, 34, 41, 51]\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff.sample(3)  #Default is without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff.sample(frac=1)  \n",
    "\n",
    "#frac is the fraction of the original dataset that you want to sample.  \n",
    "# The default is without replacement (which we want when doing permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to our original dataframe with the name labels shuffled \n",
    "\n",
    "shuffled_labels = staff[\"Groups\"].sample(frac=1, replace=False).values\n",
    "original_with_shuffled_labels = staff.copy()\n",
    "original_with_shuffled_labels[\"Shuffled Label\"] = shuffled_labels\n",
    "original_with_shuffled_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Under Null Hypothesis:  Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "We start by creating a function that simulates the difference in means for one random permutation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulated_difference(df, numeric_label, category_label,absol=False, print_ex=False):\n",
    "    \"\"\"\n",
    "    Takes: \n",
    "       - name of table\n",
    "       - column label of numerical variable\n",
    "       - column label of categorical variable\n",
    "       \n",
    "    Returns: Difference of means of the two groups\n",
    "    \"\"\"\n",
    "    \n",
    "    # array of shuffled labels\n",
    "    shuffled_labels = df[category_label].sample(frac=1, replace=False).values\n",
    "    \n",
    "    # table of numerical variable and shuffled labels\n",
    "    \n",
    "    original_with_shuffled=df.copy()\n",
    "    original_with_shuffled[\"Shuffled Label\"] = shuffled_labels\n",
    "    \n",
    "    if print_ex==True:\n",
    "        print(original_with_shuffled[[numeric_label, category_label,\"Shuffled Label\"]])\n",
    "    \n",
    "    \n",
    "    if absol==True:\n",
    "        return difference_of_means(original_with_shuffled, numeric_label, 'Shuffled Label', absol=True)   \n",
    "    else:\n",
    "        return difference_of_means(original_with_shuffled, numeric_label, 'Shuffled Label')   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_simulated_difference(births_df,\"Birth Weight\", \"Maternal Smoker\", print_ex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1d\n",
    "\n",
    "Repeat this process for n=10000 simulations and graph the empirical histogram of the difference in means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 10000\n",
    "\n",
    "\n",
    "simulated_statistics_ab = np.array([one_simulated_difference(births_df,\"Birth Weight\", \"Maternal Smoker\") for i in range(repetitions)]) # SOLUTION\n",
    "\n",
    "\n",
    "plt.hist(simulated_statistics_ab, density = True, ec=\"white\")\n",
    "plt.xlabel('Difference in average weights')\n",
    "plt.ylabel('Percent per Unit')\n",
    "plt.title('Prediction Under the Null Hypothesis')\n",
    "#Plot a point with the observed test statistic\n",
    "plt.scatter(observed_difference, -0.002, color='red', s=70);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1e\n",
    "\n",
    "Compute `empirical_p`, the empirical p-value based on `simulated_statistics_ab` (the empirical distribution of the test statistic) and `observed_difference` (the observed value of the test statistic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_p = np.count_nonzero(simulated_statistics_ab<= observed_difference) / len(simulated_statistics_ab)\n",
    "empirical_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### CONCLUSION OF TEST:  Question 1f\n",
    "\n",
    "Based on this computed empirical p-value, and our pre-determined significance level of 0.01, do we accept or reject the null hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**: The empirical p-value is 0, meaning that none of the 10,000 permuted samples resulted in a difference of -9.27 or lower. **This is only an approximation. The exact chance of getting a difference in that range is not 0.** But it is vanishingly small, according to our simulation, therefore $p<=0.01$, so we  **reject the null hypothesis and accept the alternative hypothesis** and our test results are highly statistically significant.\n",
    "\n",
    "\n",
    "\n",
    "\"In the population, the babies of the mothers who smoke have a lower birth weight, on average, than the babies of the non-smokers and this result is highly statistically significant\"\n",
    "\n",
    "\n",
    "Since this was an observational study (NOT a randomized control trial) we CANNOT conclude that smoking causes the lower birth rate, only that there was an association between the two. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice, if we look at other variables in the dataset, it is possible that one of the other variables\n",
    "# had a casual relationship with Birth Weight.  There is no way to make a casual conclusion without\n",
    "# doing a randomized controlled trial, which we can't ethically do in this situation.\n",
    "\n",
    "births_df.groupby(\"Maternal Smoker\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Controlled Trials\n",
    "\n",
    "\n",
    "\n",
    "Our methods for comparing two samples have a powerful use in the analysis of randomized controlled experiments. Since the treatment and control groups are assigned randomly in such experiements, differences in their outcomes can be compared to what would happen just due to chance if the treatment had no effect at all. If the observed differences are more marked than what we would predict as purely due to chance, we will have evidence of causation. Because of the unbiased assignment of individuals to the treatment and control groups, differences in the outcomes of the two groups can be ascribed to the treatment.\n",
    "\n",
    "The key to the analysis of randomized controlled experiments is understanding exactly how chance enters the picture. This helps us set up clear null and alternative hypotheses. Once that’s done, we can simply use the methods of the previous sections to complete the analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Example 2: Treating Low Back Pain\n",
    "\n",
    "\n",
    "\n",
    "Low-back pain in adults can be very persistent and hard to treat. Common methods run the gamut from corticosteroids to acupuncture. A randomized controlled trial (RCT) (https://pubmed.ncbi.nlm.nih.gov/11376175/) examined the effect of using Botulinum Toxin A (BTA) as a treatment. Botulinum toxin is a neurotoxic protein that causes the disease botulism; Wikipedia says that botulinum “is the most acutely lethal toxin known.” There are seven types of botulinum toxin. Botulinum Toxin A is one of the types that can cause disease in humans, but it is also used in medicine to treat various diseases involving the muscles. The RCT analyzed by Foster, Clapp, and Jabbari in 2001 examined it as a treatment for low back pain.\n",
    "\n",
    "\n",
    "Thirty one patients with low-back pain were randomized into treatment and control groups, with 15 in the treatment group and 16 in control. The control group was given normal saline, and the trials were run double-blind so that neither doctors nor patients knew which group they were in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eight weeks after the start of the study, nine of the 15 in the treatment group and two of the 16 in the control group had pain relief (according to a precise definition used by the researchers). These data are in the file `bta.csv` and appear to show that the treatment has a clear benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botox = pd.read_csv('data/bta.csv')\n",
    "botox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null and Alternative Hypotheses and Significance Level:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null Hypothesis:** The distribution of all 31 potential “treatment” outcomes is the same as that of all 31 potential “control” outcomes. Botulinum toxin A does nothing different from saline; the difference in the two samples is just due to chance.\n",
    "\n",
    "**Alternative Hypothesis:** The distribution of 31 potential “treatment” outcomes is different from that of the 31 control outcomes. The treatment does something different from the control.\n",
    "\n",
    "\n",
    "\n",
    "**Significance Level:** As is standard with medical studies, we will test this at a significance level of $\\alpha = 0.01$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choosing Test Statistic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice that the alternative is not specifying that the treatment helps – just that it is different from the control. This is standard in medical studies because it doesn’t pre-judge which way the result might go. \n",
    "\n",
    "Notice the outcome is binary (either it helps (1) or it didn't (0)).\n",
    "\n",
    "\n",
    "Because of this, the following three test statistics are all equivalent:\n",
    " - TVD: sum(abs(dist1-dist2))/2\n",
    " - Absolute difference in proportion of successes: abs(group1prop - group2prop)\n",
    " - Absolute difference in the mean of the binary data from both distributions:  abs(group1mean - group2mean)\n",
    "\n",
    "In the code below we'll calculate this using the last format, but notice that this is equivalent to using the TVD:  **abs(treatment_mean - control_mean)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect data and calculate observed test statistic:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botox.groupby(['Group', 'Result']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botox.groupby('Group').agg({\"Result\":\"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use difference of proportions of people who had pain relief (Result=1) as the test statistic\n",
    "\n",
    "#Notice for binary data, proportion of 1's = mean\n",
    "\n",
    "#Calculate the observed test statistic.\n",
    "\n",
    "\n",
    "#observed_diff = abs(botox.groupby('Group').agg({\"Result\":\"mean\"}).iloc[1,0] - botox.groupby('Group').agg({\"Result\":\"mean\"}).iloc[0,0])\n",
    "    \n",
    "#observed_diff\n",
    "\n",
    "\n",
    "# Or we can just use our function above\n",
    "observed_diff = difference_of_means(botox, 'Result', 'Group',absol=True)\n",
    "\n",
    "observed_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle:\n",
    "\n",
    "shuffled_labels = botox[\"Group\"].sample(frac=1, replace=False).values\n",
    "    \n",
    "# table of numerical variable and shuffled labels\n",
    "    \n",
    "original_with_shuffled=botox.copy()\n",
    "original_with_shuffled[\"Shuffled Label\"] = shuffled_labels\n",
    "    \n",
    "#print (original_with_shuffled)\n",
    "\n",
    "# Calculate test statistic using shuffled labels:\n",
    "\n",
    "test_stat = abs(original_with_shuffled.groupby('Shuffled Label')[\"Result\"].mean()[1] - botox.groupby('Group')[\"Result\"].mean()[0])\n",
    "    \n",
    "print (\"Simulated test statistic is:\", test_stat)\n",
    "\n",
    "\n",
    "\n",
    "# Or we could have done all of these steps just using our function above:\n",
    "#one_simulated_difference(botox, 'Result', 'Group',print_ex=True, absol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_simulated_difference(botox, 'Result', 'Group',print_ex=True, absol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat simulations and plot empirical histogram of test statistic:\n",
    "\n",
    "repetitions = 100000\n",
    "\n",
    "\n",
    "simulated_diffs = np.array([one_simulated_difference(botox, 'Result', 'Group', absol=True) for i in range(repetitions)]) # SOLUTION\n",
    "\n",
    "\n",
    "plt.hist(simulated_diffs, density = True, ec=\"white\", bins=[0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.xlabel('Test Statistic: abs(treatment minus control)')\n",
    "plt.ylabel('Percent per Unit')\n",
    "plt.title('Distribution Under the Null Hypothesis')\n",
    "#Plot a point with the observed test statistic\n",
    "plt.scatter(observed_diff, -0.002, color='red', s=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate p-value and make conclusion from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value\n",
    "sum(simulated_diffs >= observed_diff)/len(simulated_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small empirical p-value. The observed statistic is in the tail of the empirical histogram of the test statistic generated under the null hypothesis.\n",
    "\n",
    "Since $p \\leq .01$ the result is highly statistically significant. The test favors the alternative hypothesis over the null. The evidence supports the hypothesis that the treatment is doing something.\n",
    "\n",
    "The actual study reports a P-value of 0.009, or 0.9%, which is very close to our empirical value.\n",
    "\n",
    "## Note about Causality\n",
    "Because the trials were randomized, the test is **evidence that the treatment causes the difference.** The random assignment of patients to the two groups ensures that there is no confounding variable that could affect the conclusion of causality.\n",
    "\n",
    "If the treatment had not been randomly assigned, our test would still point toward an association between the treatment and back pain outcomes among our 31 patients. But beware: without randomization, this association would not imply that the treatment caused a change in back pain outcomes. For example, if the patients themselves had chosen whether to administer the treatment, perhaps the patients experiencing more pain would be more likely to choose the treatment and more likely to experience some reduction in pain even without medication. Pre-existing pain would then be a confounding factor in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Meta-Analysis\n",
    "While the Randomized Control Trial does provide evidence that the botulinum toxin A treatment helped patients, **a study of 31 patients isn’t enough to establish the effectiveness of a medical treatment. This is not just because of the small sample size. Our results in this section are valid for the 31 patients in the study, but we are really interested in the population of all possible patients.**\n",
    "\n",
    "In 2011, a group of researchers performed a meta-analysis of the studies on the treatment. That is, they identified all the available studies of such treatments for low-back pain and summarized the collated results.\n",
    "\n",
    "There were several studies but not many could be included in a scientifically sound manner: “We excluded evidence from nineteen studies due to non-randomisation, incomplete or unpublished data.” Only three randomized controlled trials remained, one of which is the one we have studied in this section. The meta-analysis gave it the highest assessment among all the studies (LBP stands for low-back pain): “We identified three studies that investigated the merits of BoNT for LBP, but only one had a low risk of bias and evaluated patients with non-specific LBP (N = 31).”\n",
    "\n",
    "**Putting it all together, the meta-analysis concluded, “There is low quality evidence that BoNT injections improved pain, function, or both better than saline injections and very low quality evidence that they were better than acupuncture or steroid injections. … Further research is very likely to have an important impact on the estimate of effect and our confidence in it. Future trials should standardize patient populations, treatment protocols and comparison groups, enlist more participants and include long-term outcomes, cost-benefit analysis and clinical relevance of findings.”**\n",
    "\n",
    "It takes a lot of careful work to establish that a medical treatment has a beneficial effect. Knowing how to analyze randomized controlled trials is a crucial part of this work. Now that you know how to do that, you are well positioned to help medical and other professions establish cause-and-effect relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The effect of simulation size on empirical p-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests = pd.DataFrame(columns=['simulations', 'p-value for observed test statistic of 0.475'])\n",
    "    \n",
    "for num_sims in [1000, 10000, 20000, 100000]:\n",
    "    for k in np.arange(10):\n",
    "        sim = np.array([one_simulated_difference(botox, 'Result', 'Group', absol=True) for i in range(num_sims)]) # SOLUTION\n",
    "        tests.loc[len(tests.index)] = [num_sims, sum(sim >= observed_diff)/num_sims] \n",
    " \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=tests, x=\"p-value for observed test statistic of 0.475\", hue=\"simulations\", multiple=\"stack\")\n",
    "plt.scatter(.009, -0.002, color='red', s=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
