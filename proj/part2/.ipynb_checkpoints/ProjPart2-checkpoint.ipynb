{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4c3c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ProjPart2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889297b-c459-4d2e-bc22-bdd4dc0d7bc0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project - Part 2:Predicting Housing Prices in Cook County\n",
    "\n",
    "## Due Date: Thursday, April 24th, 11:59 PM MT on Gradescope\n",
    "\n",
    "## NO LATE SUBMISSIONS will be accepted - you must plan accordingly.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity.  However a key step in learning and retention is **creating solutions on your own.**  \n",
    "\n",
    "Below are examples of acceptable vs unacceptable use of resources and collaboration when doing the Project assignments in CSCI 3022.\n",
    "\n",
    "\n",
    "The following would be some **examples of cheating** when working on the Project in CSCI 3022.  Any of these constitute a **violation of the course's collaboration policy and will result in an F in the course and a trip to the honor council**.   \n",
    "\n",
    "\n",
    " - Consulting web pages that may have a solution to a given homework problem or one similar is cheating.  However, consulting the class notes, and web pages that explain the material taught in class but do NOT show a solution to the homework problem in question are permissible to view.  Clearly, there's a fuzzy line here between a valid use of resources and cheating. To avoid this line, one should merely consult the course notes, the course textbook, and references that contain syntax and/or formulas.\n",
    " - Copying a segment of code or math solution of three lines or more from another student from a printout, handwritten copy, or by looking at their computer screen \n",
    " - Allowing another student to copy a segment of your code or math solution of three lines or more\n",
    " - Taking a copy of another student's work (or a solution found online) and then editing that copy\n",
    " - Reading someone elseâ€™s solution to a problem on the Project before writing your own.\n",
    " - Asking someone to write all or part of a program or solution for you.\n",
    " - Asking someone else for the code necessary to fix the error for you, other than for simple syntactical errors\n",
    " \n",
    "\n",
    "\n",
    "On the other hand, the following are some **examples of things which would NOT usually be\n",
    "considered to be cheating**:\n",
    " - Working on a Project problem on your own first and then discussing with a classmate a particular part in the problem solution where you are stuck.  After clarifying any questions you should then continue to write your solution independently.\n",
    " - Asking someone (or searching online) how a particular construct in the language works.\n",
    " - Asking someone (or searching online) how to formulate a particular construct in the language.\n",
    " - Asking someone for help in finding an error in your program.  \n",
    " - Asking someone why a particular construct does not work as you expected in a given program.\n",
    "   \n",
    "\n",
    "To test whether you are truly doing your own work and retaining what you've learned you should be able to easily reproduce from scratch and explain a Project solution that was your own when asked in office hours by a TA/Instructor or on a quiz/exam.   \n",
    "\n",
    "\n",
    "If you have difficulty in formulating the general solution to a problem on your own, or\n",
    "you have difficulty in translating that general solution into a program, it is advisable to see\n",
    "your instructor or teaching assistant rather than another student as this situation can easily\n",
    "lead to a, possibly inadvertent, cheating situation.\n",
    "\n",
    "We are here to help!  Visit HW Hours and/or post questions on Piazza!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe8bcb-ec8c-44fa-ae82-2d3fd3e8f4f9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In Part 1 of this project, you performed some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Then, you added a few new features to the dataset, cleaning the data as well in the process.\n",
    "\n",
    "In Part 2 of the project, you will specify and fit a linear model to a few features of the housing data to predict housing prices. Next, we will analyze the error of the model and brainstorm ways to improve the model's performance. Finally, we'll delve deeper into the implications of predictive modeling within the Cook County Assessor's Office (CCAO) case study, especially because statistical modeling is how the CCAO valuates properties. Given the history of racial discrimination in housing policy and property taxation in Cook County, consider the impacts of your modeling results as you work through this assignment - and think about what fairness might mean to property owners in Cook County.\n",
    "\n",
    "After this part of the project, you should be comfortable with:\n",
    "- Implementing a data processing pipeline using `pandas`\n",
    "- Using `scikit-learn` to build and fit linear models\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Manual | Points\n",
    "----|----|----\n",
    "1abd | Yes | 5\n",
    "1c | No | 1\n",
    "2acd | No| 4\n",
    "2b | Yes | 3\n",
    "3 | No | 2\n",
    "4 | No | 10\n",
    "5 | No | 7\n",
    "6 | Combo | 14\n",
    "7 | Yes | 4\n",
    "Total | | 50 | 32\n",
    "Extra Credit| Yes| Up to +20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c5cda-c5a0-4a4d-8c08-c61b323e825a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds100_utils import run_linear_regression_test\n",
    "\n",
    "def get_hash(num):\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854e2e6-252b-4f1f-b488-dbad2738689c",
   "metadata": {},
   "source": [
    "Let's load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a24eae-51fb-476a-a30c-d6a2dc70c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS  - DON'T COMMENT THIS OUT - it is needed for the autograder.\n",
    "\n",
    "with zipfile.ZipFile('data/cook_county_data.zip') as item:\n",
    "    item.extractall(path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d455e3-8e46-4fc8-b1f1-3a110ee94bcc",
   "metadata": {},
   "source": [
    "This dataset is split into a training/validation set, and a test set. Importantly, the test set does not contain values for our target variable, Sale Price. In this project, you will train a model on the training and validation sets and then use this model to predict the Sale Prices of the test set. In the cell below, we load the training and validation sets into the DataFrame `tr_val_data` and the test set into the DataFrame `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866f09a-e957-4f34-a4a5-9123328768d2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tr_val_data = pd.read_csv(\"data/cook_county_train_val.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"data/cook_county_contest_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc50148-74ee-41f6-aa08-9f82e5360ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc7691-c277-49e6-85d8-58095387be94",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd037cd-a127-4715-9692-83ed4df968ba",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 204792 observations and 62 features in training data\n",
    "assert tr_val_data.shape == (204792, 62)\n",
    "# 55311 observations and 61 features in test data\n",
    "assert test_data.shape == (55311, 61)\n",
    "# Sale Price is provided in the training/validation data\n",
    "assert 'Sale Price' in tr_val_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df15c1-ba1b-4cb2-8f12-ecfe8a5af841",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's remind ourselves of the data available to us in the Cook County dataset. Remember, a more detailed description of each variable is included in `data/codebook.txt`, which is in the same directory as this notebook). **If you did not attempt Project Part 1,** you should take some time to familiarize yourself with the codebook before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cecf768-8350-4b23-8d82-ff64d0aff66f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_val_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386e337-dd76-4578-858a-b9f57d4e84f2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Human Context and Ethics\n",
    "\n",
    "In this part of the project, we will explore the human context of our housing dataset.\n",
    "\n",
    "**You should read the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/117881/files/77796404?module_item_id=6056298) on Canvas explaining the context and history surrounding this dataset before attempting this section.**\n",
    "\n",
    "<br>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9639cc-69e1-4079-846d-f9f774b7ea79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1a\n",
    "In this project we are essentially trying to answer the question.  \"How much is a house worth?\" \n",
    " - Who might be interested in an answer to this question? **Please list at least three different parties (people or organizations) and then describe whether each one has an interest in seeing the housing price to be either high or low.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d3b6f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887156f2-4ffd-444d-939f-19f744de72e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1b\n",
    "\n",
    " - 1bi).  Which of the following scenarios strike you as unfair and why? You can choose more than one. There is no single right answer, but you must explain your reasoning.\n",
    " - 1bii). Would you consider some of these scenarios more (or less) fair than others? Why?\n",
    "\n",
    "Scenario A: A homeowner whose home is assessed at a higher price than it would sell for.  \n",
    "Scenario B: A homeowner whose home is assessed at a lower price than it would sell for.  \n",
    "Scenario C: An assessment process that systematically overvalues inexpensive properties and undervalues expensive properties.  \n",
    "Scenario D: An assessment process that systematically undervalues inexpensive properties and overvalues expensive properties.\n",
    "\n",
    "\n",
    "Write your full answers to both parts in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349d933",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27732048-de45-46bf-b5e7-a6733cd323c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Consider a model that is fit to $n = 50$ training observations. We denote the response as $y$ (Log Sale Price), the prediction as $\\hat{y}$, and the corresponding residual to be $y - \\hat{y}$.   \n",
    "\n",
    "Typically when we make a residual plot, we plot the residuals vs the predictions $\\hat{y}$.  \n",
    "\n",
    "However, in the plot below, we are plot the residuals vs the actual price of homes in the data $y$ (Log Sale Price), to be able to visualize for which prices of homes the model is generally overvaluing vs undervaluing. \n",
    "\n",
    "\n",
    "\n",
    "Which plot below corresponds to a model that might make property assessments that result in regressive taxation? (Refer to the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/117881/files/77796404?module_item_id=6056298) for a reminder of the definition of regressive taxation).  Assume that all three plots use the same vertical scale and that the horizontal line marks $y - \\hat{y} = 0$. Assign `q1c` to the string letter corresponding to your plot choice.\n",
    "\n",
    "**Hint:** When a model overvalues a property (predicts a `Sale Price` greater than the actual `Sale Price`), what are the relative sizes of $y$ and $\\hat{y}$? What about when a model undervalues a property?\n",
    "\n",
    "**Graded Via Hidden Test in Gradescope** Since this is a multiple choice question, the in-notebook check for this problem only checks that you entered a valid string, it does **NOT** check for correctness of your answer for this question - that will be graded when you submit to Gradescope.  \n",
    "\n",
    "<img src='img/res_plots.png' width=\"900px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913057c-7bd8-4c28-9b4e-c41b2b47a834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6c08f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8c5ac-4463-4b3c-87cc-0afafecb1353",
   "metadata": {},
   "source": [
    "## The CCAO Dataset\n",
    "\n",
    "You'll work with the dataset from the Cook County Assessor's Office (CCAO) in Illinois. This government institution determines property taxes across most of Chicago's metropolitan areas and nearby suburbs. In the United States, all property owners must pay property taxes, which are then used to fund public services, including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models considering multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "This system, however, is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing \"[racially discriminatory assessments and taxes](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html).\" The lawsuit included claims that the assessor's office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines: Wealthy homeowners, who were typically white, paid less in property taxes, whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, \"[The Tax Divide](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html)\", delves into how this was uncovered: After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments had been so far off the mark for so many years.\" You can read more about their investigation  [in this news article](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "**You should read the [Project Case Study.pdf](https://canvas.colorado.edu/courses/117881/files/77796404?module_item_id=6056298)  explaining the history about this dataset before answering the following question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e46c1-ef8c-4d10-be2d-fc5f273cc00a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1d\n",
    "\n",
    " - 1di).  What were the central problems with the earlier property tax system in Cook County as reported by the Chicago Tribune?\n",
    " - 1dii). What were the primary causes of these problems? (Note: in addition to reading the paragraph above you will need to **read the [Project Case Study.pdf](https://canvas.colorado.edu/courses/117881/files/77796404?module_item_id=6056298\n",
    " - )  explaining the context and history of this dataset  before answering this question).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d96ba",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3209a-f05f-49f6-9acc-942340dbaf34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: More EDA\n",
    "\n",
    "<br>\n",
    "\n",
    "In good news you have already done a lot of EDA with this dataset in Project 1. \n",
    "\n",
    "Before fitting any model, we should check for any missing data, duplicate data and/or unusual outliers.\n",
    "\n",
    "We know from Project Part 1, that the granularity of this dataset is that each row represents data from the sale of a specific property in Cook county between 2013-2019.\n",
    "\n",
    "### Question 2a: More EDA\n",
    "\n",
    "\n",
    "We'll start by checking to make sure that there aren't any duplicate rows (i.e. rows in which every entry is exactly the same).   We'll consider any duplicate rows to be a data entry error, as each row should represent a unique sale. \n",
    "\n",
    "\n",
    "As an example, let's say one sale is duplicated three times (i.e. 3 duplicate rows for that specific sale) and a different sale is duplicated 5 times.  In that scenario we would say there are 2 unique property sales that have duplicates, and we would need to remove a total of (5+3-2=6) extra rows of duplicate data.  \n",
    "\n",
    "\n",
    "How many unique property sales in the `tr_val_data` have exact duplicates and what is the total number of duplicate rows we should remove? \n",
    "\n",
    "Assign your answers to `count_duplicate_properties` and `count_duplicate_rows_to_remove` below.\n",
    "\n",
    "(Again, so in the toy example above, count_duplicate_properties=2 and count_duplicate_rows_to_remove=6).  \n",
    "\n",
    "HINT:  Panda's `df.duplicated()` function may be useful here:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b59b0c-0195-41ff-b7cf-bad6a7374342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "count_duplicate_properties = ...\n",
    "\n",
    "count_duplicate_rows_to_remove = ...\n",
    "\n",
    "print(\"There are \", count_duplicate_properties, \"unique property sales with exact duplicates.\")\n",
    "print(\"There are \", count_duplicate_rows_to_remove, \"a total of duplicate rows that we'll need to remove when we write our cleaning function below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e5e94",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29121136-7c87-4604-a66d-cbfdeb4fbc42",
   "metadata": {},
   "source": [
    "We will create a function in part 2d to clean the data (and remove these duplicates), but first we will look for any other unusual outliers in the data that we will want to remove as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ead77-03f9-4d6b-ba19-928007b3a47e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "### Question 2b: \n",
    "\n",
    "Since we're trying to predict `Sale Price`, next we'll look for missing or unusual outliers in that field.\n",
    "\n",
    "Examine the `Sale Price` column in the `tr_val_data` DataFrame and answer the following questions:\n",
    "\n",
    "\n",
    " - 2bi).  Does the `Sale Price` data have any missing, N/A, negative or 0 values for the data?  If so, propose a way to handle this.\n",
    "\n",
    " - 2bii).  Does the `Sale Price` data have any unusually large outlier values?  If so, propose a cutoff to use for throwing out large outliers, and justify your reasoning).  \n",
    "\n",
    " - 2biii).  Does the `Sale Price` data have any unusually small outlier values?  If so, propose a cutoff to use for throwing out small outliers, and justify your reasoning.  \n",
    " \n",
    " \n",
    "Below are three cells.  The first is a Markdown cell for you to write up your responses to all 3 parts above.\n",
    "The second two are code cells that are available for you to write code to explore the outliers and/or visualize the Sale Price data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12ca0a-a4b6-472e-8ce5-26bc89245825",
   "metadata": {},
   "source": [
    "### Question 2b i, ii, iii answer cell:   *Type your responses to all three parts in this cell...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e6bba-c52e-45c5-adec-d3ac2b615450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# your code exploring Sale Price above this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d68918-1f04-43c4-a33b-64ddeb90a549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# optional extra cell for exploring code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4195f-0695-4c6d-a932-4bbd5f1f4710",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Pure Market Filter**\n",
    "\n",
    "As you (hopefully) noticed, there are quite a few small values for the Sale Price of a home that don't make sense.  This can happen when someone sells a house to a relative for $\\$1$ or some other price that is not reflective of the true market value.  There are also several extremely large outliers (houses that sold for more than $10 million) that don't accurately capture the true market value of a home.\n",
    "\n",
    "It turns out, there's actually an indicator feature already available in the dataset to help filter out any sale transactions that aren't considered \"Pure Market Transactions\"  (for example, when someone sells a house to a relative for $\\$1$, we don't consider that a transaction driven by the true market value of the house).\n",
    "\n",
    "\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "To understand the cutoffs used by this filter, determine the max and min Sale Price values for the subset of data in the training_val dataset with the indicator `Pure Market Filter` = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8506f-c082-4864-9046-e9b5c1bc67ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_Sale_Price_filtered = ...\n",
    "\n",
    "min_Sale_Price_filtered = ...\n",
    "\n",
    "print(\"When considering only pure market sales, the max Sale Price of properties in the data is $\", max_Sale_Price_filtered)\n",
    "print(\"and the min Sale Price is $\", min_Sale_Price_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e82021",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21ac9e-7623-4676-a2d3-5599e2b0bc30",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2d\n",
    "\n",
    "Create a function `clean_data` that takes in a dataframe of property sales `data` and cleans the data as follows:\n",
    "\n",
    " - Removes duplicate rows (for example, instead of 3 rows of duplicate data for a unique property sale, we would only keep 1 row with that information),\n",
    " - Filters out outliers in Sale Price by only keeping rows with \"Pure Market Filter\" = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d87b0-6baa-4f19-ae89-3a08c5eb31e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(data):\n",
    "\n",
    "    '''\n",
    "    Cleans the data DataFrame by removing duplicate rows and removing rows with 'Pure Market Filter = 1'\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame):  DataFrame to clean\n",
    "        \n",
    "    Return:\n",
    "        Cleaned DataFrame\n",
    "    '''\n",
    "    \n",
    "    da = data.copy()\n",
    "\n",
    "    ...\n",
    "    # Do NOT reset the index of the cleaned data.\n",
    "    \n",
    "    return da\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafa78e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3b06e-a840-466a-a35c-2aeaa96dcb7b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bfbb7-a367-4bef-aa36-ab2cbf4ba27e",
   "metadata": {},
   "source": [
    "In this project we are going to create and compare models to predict the Sale Price of properties in Cook County.  \n",
    "\n",
    "If we used all the available data to fit and compare our models, we would not have a way to estimate model performance on **unseen data** such as the test set in `cook_county_contest_test.csv`.\n",
    "\n",
    "We'll start by using Simple Cross Validation to fit and evaluate our models.  This involves taking the `tr_val_clean` data and actually splitting it into a training and validation set.  \n",
    "\n",
    "We will use the training set to fit each model's parameters and the validation set to evaluate how well each model will likely perform on unseen data drawn from the same distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ad91a-0444-4f17-af81-240002c6c9e6",
   "metadata": {},
   "source": [
    "In the cell below, complete the function train_val_split that splits an input DataFrame data into two smaller DataFrames named train and validation, where validation contains the **first** 20% of the rows in input DataFrame and train contains the remaining 80% of the data.  Do not shuffle the input DataFrame inside the function. You should not be importing any additional libraries for this question.\n",
    "\n",
    "(If the cutoff for the first 20% of the data is not an exact integer, round down to the nearest integer).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81141b-ac30-475e-87bc-47d150f0a855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_val_split(data):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame `data` and splits it into two smaller DataFrames \n",
    "    named `validation` and `train` where validation is the first 20% of the rows and train \n",
    "    is the last 80% of the rows, respectively. \n",
    "    If the the first 20% of the data is not an exact integer, round down to the nearest integer.\n",
    "    Do not shuffle or re-index the data DataFrame.  \n",
    "    \"\"\"\n",
    "    da = data.copy()\n",
    "    \n",
    "    \n",
    "    ...\n",
    "    \n",
    "    validation = ...\n",
    "    train = ...\n",
    "   \n",
    "    \n",
    "    return train, validation\n",
    "\n",
    "\n",
    "\n",
    "# To randomize the validation and training sets, we will shuffle the data once before \n",
    "# running it through the train_val split function\n",
    "# Do not change the random_state seed in this code - it will ensure reproducibility so \n",
    "# you can pass the in-notebook test cases\n",
    "tr_val_data_shuffled = tr_val_data.sample(frac=1, random_state=18)\n",
    "\n",
    "\n",
    "\n",
    "# Clean the shuffled data\n",
    "tr_val_clean = clean_data(tr_val_data_shuffled) \n",
    "\n",
    "# Create the train/val split on the cleaned, shuffled data:\n",
    "tr, val = train_val_split(tr_val_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf8c7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af9846-92fd-45c2-99c5-55ed0f18e62a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Fitting a Simple Linear Regression Model\n",
    "\n",
    "In Part 1 of the project, you plotted the log-transformed Sale Price vs the log-transformed total area covered by the building (in square feet)  and saw there was a positive linear association.  Let's start the modeling process by fitting a simple linear regression model using this predictor.  \n",
    "\n",
    "Our first model will take the form:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Log Building Square Feet})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc99c7-cda3-4a06-a9f1-8b0566d1616a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "## Modeling Step 1:  Feature Transformation\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## Create a pipeline to process the data\n",
    "\n",
    "It is time to prepare the training and validation data for the model we proposed above. \n",
    "\n",
    "In Project Part 1, you wrote a few functions that added features to the dataset. Instead of calling them manually one by one each time, it is best practice to encapsulate all of this feature engineering into one \"pipeline\" function. Defining and using a pipeline reduces all the feature engineering to just one function call and ensures that the same transformations are applied to all data.  \n",
    "\n",
    "\n",
    "### Question 4a:\n",
    "\n",
    "\n",
    "For an example of how to work with pipelines, you will complete the missing code in the `process_data_m1` function in the cell below. \n",
    "\n",
    "\n",
    "In particular, the cell below completes the following steps:\n",
    "\n",
    "  1. Creates a function `process_data_m1` to perform the following feature engineering:  \n",
    "     - Applies log transformations to the `Sale Price` and the `Building Square Feet` columns to create two new columns, `Log Sale Price` and `Log Building Square Feet`.\n",
    "     - Outputs a DataFrame with only the columns used in model 1 (that is `Log Sale Price` , `Log Building Square Feet`)\n",
    " \n",
    " 2. The code in the cell then runs `process_data_m1` separately on the training data and then the validation data.  It then creates the design matrix $\\mathbb{X}$ and the observed vector $\\mathbb{Y}$ for both the training data and the validation data (and saves them in the variable names `X_train_m1`, `Y_train_m1`, `X_valid_m1`, `Y_valid_m1`). Note that $\\mathbb{Y}$ refers to the transformed `Log Sale Price`, not the original `Sale Price`. **X  should be a `pandas` DataFrame and the observed Y vector should be a `pandas` Series.**\n",
    "\n",
    "\n",
    "Fill in the missing code in the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc41b8-08cc-43b6-90dd-2af7ee51c2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data_m1(df):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame of cleaned data and performs feature engineering to use for Model 1.\n",
    "\n",
    "    Outputs a DataFrame with only the features and response/output used in model 1 (that is `Log Sale Price` , `Log Building Square Feet`)\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    data=df.copy()\n",
    "    \n",
    "    # Add a column \"Log Sale Price\" to the `data` DataFrame:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    # Add a column \"Log Building Square Feet\" to the `data` DataFrame:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    # Select the feature and the output/response used in model 1:\n",
    "    \n",
    "    data = data[['Log Building Square Feet', 'Log Sale Price']]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Process both the training and validation data: \n",
    "\n",
    "processed_train_m1 = process_data_m1(tr)\n",
    "\n",
    "processed_val_m1 = process_data_m1(val)\n",
    "\n",
    "\n",
    "# Create X (dataframe) and Y (series) to use to train the model:\n",
    "X_train_m1 = processed_train_m1.drop(columns = \"Log Sale Price\")\n",
    "y_train_m1 = processed_train_m1[\"Log Sale Price\"]\n",
    "\n",
    "\n",
    "# Create X (dataframe) and Y (series) to use to validate the model:\n",
    "X_valid_m1 = processed_val_m1.drop(columns = \"Log Sale Price\")\n",
    "y_valid_m1 = processed_val_m1[\"Log Sale Price\"]\n",
    "\n",
    "# Take a look at the results\n",
    "print(\"Training Data: X\")\n",
    "display(X_train_m1.head())\n",
    "print(\"Training Data: y\")\n",
    "display(y_train_m1.head())\n",
    "\n",
    "\n",
    "print(\"Validation Data: X\")\n",
    "display(X_valid_m1.head())\n",
    "print(\"Validation Data: y\")\n",
    "display(y_valid_m1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f004824",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fce59-2917-4e15-b9f0-52c798505aec",
   "metadata": {},
   "source": [
    "## Modeling Step 2:  Create a linear model\n",
    "\n",
    "Next we'll use `sci-kit learn` to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2657bb-6755-4efc-a62d-d57cd524bae2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "\n",
    "We first initialize a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object for our model. \n",
    "\n",
    "\n",
    "Fill in the missing code below to fit the model using the training set.  Then output the model's predictions for both the training and validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b058fed-39c4-4320-a548-daa2bbe76576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_model_m1 = lm.LinearRegression()\n",
    "\n",
    "# Fit the model using the processed training data:\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "# Compute the predicted y values from linear model 1 (in units log sale price) \n",
    "# using the training data as input:\n",
    "\n",
    "y_predict_train_m1 = ...\n",
    "\n",
    "# Compute the predicted y values from linear model 1 (in units log(sale price))\n",
    "# using the validation data as input:\n",
    "\n",
    "y_predict_valid_m1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56b4cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb1cc7-d7cb-4e5d-87de-caba4317d54f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Modeling Step 3:  Model Evaluation Using RMSE\n",
    "\n",
    "\n",
    "We'll compare the performance of our models using the Root Mean Squared Error (RMSE) function.\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in the set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of houses}}}$$\n",
    "\n",
    "\n",
    "### QUESTION 4c:\n",
    "\n",
    "Complete the code below for the funtion RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a37bb0-c38b-4602-a300-d04beaf4e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915116d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307071be-d358-4881-8954-2ee41a390c8c",
   "metadata": {},
   "source": [
    "### Keeping track of all the models.\n",
    "\n",
    "In this notebook (and in life) we will want to keep track of all our models. \n",
    "For this part of the project you will be creating 3 different versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f634cf-70bf-4131-84af-f4a8a255dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to create arrays to store the RMSE information from the models\n",
    "\n",
    "model_names=[\"M1: log(bsqft)\", \"M2\", \"M3\"]\n",
    "\n",
    "# Create arrays where we can keep track of training and validation RMSE for each model\n",
    "\n",
    "training_error_log = np.zeros(4)\n",
    "validation_error_log = np.zeros(4)\n",
    "\n",
    "training_error = np.zeros(4)\n",
    "validation_error = np.zeros(4)\n",
    "\n",
    "# Array to track cross validation errors average RMSE errors  \n",
    "\n",
    "cv_error = np.zeros(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32039d-9ee0-4d35-b821-58f7e9db4465",
   "metadata": {},
   "source": [
    "### QUESTION 4d:\n",
    "\n",
    "\n",
    "\n",
    "In the cell below use your `rmse` function to calculate the training error and validation error for model 1.\n",
    "\n",
    "Assign the RMSE of the predicted log sale prices and the actual log sale prices to the following variables: \n",
    "\n",
    " `training_error_log[0]`  and    `validation_error_log[0]`\n",
    "\n",
    "\n",
    "Since the target variable we are working with is log-transformed, it can also be beneficial to transform it back to its original form so we will have more context on how our model is performing when compared to actual housing prices.  In other words we want the RMSE **with regard to `Sale Price`**. Remember to exponentiate your predictions and response vectors before computing the RMSE using the `rmse` function and assign it to the following:\n",
    "\n",
    "`training_error[0]` and    `validation_error[0]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8378d1-890d-4ed4-afb6-9ce74c6935e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and validation RMSE for the model (in units log sale price)\n",
    "\n",
    "training_error_log[0] = ...\n",
    "validation_error_log[0]= ...\n",
    "\n",
    "\n",
    "# Training and validation RMSE for the model (in its original dollar values before the log transform)\n",
    "\n",
    "training_error[0] = ...\n",
    "validation_error[0] = ...\n",
    "\n",
    "print(\"1st Model \\nTraining RMSE: $ {}\\nValidation RMSE: $ {}\\n\".format(training_error[0], validation_error[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cd71a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2f9d1-5f90-47e1-a18d-85c7ba16c033",
   "metadata": {},
   "source": [
    "## Modeling Step 4: Cross Validation\n",
    "\n",
    "To check that the validation RMSE is representative of the dataset we'll also perform a 5-fold cross validation on the model.\n",
    "\n",
    "Scikit-learn has built-in support for cross-validation. \n",
    "\n",
    "Run the cell below to see how the SKlearn KFold object breaks up the data into 5 folds (by providing the positional indices: purely integer-location based indexing for selection by position, i.e. what you would use in .iloc) for the training and validation sets for each fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dcb09-4d55-4f02-8114-87e42c7082a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell and read through the output to understand how kf.split returns the positional indices for each split:\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5) \n",
    "\n",
    "i = 1\n",
    "\n",
    "a = []\n",
    "\n",
    "for train_idx, valid_idx in kf.split(tr_val_clean):\n",
    "    print (\"positional (iloc) indices for training data for fold\", i)\n",
    "    print (train_idx)\n",
    "    print (\"positional (iloc) indices for validation data for fold\", i)\n",
    "    print (valid_idx)\n",
    "    i = i+1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f69e88-4dd5-4e43-be31-0293af2a3eb6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question 4e:\n",
    "\n",
    "To better understand how cross-validation works, complete the following function which cross-validates a given model.\n",
    "\n",
    "Use sklearn's KFold.split [documentation](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.KFold.html) function to get 5 splits on the training data. Note that split returns the positional indices of the data for that split.\n",
    "\n",
    "For each split:\n",
    " - Select the training and validation rows and columns based on the split indices and features.\n",
    " - Compute the RMSE on the validation split (in units Sale Price, NOT log Sale Price)\n",
    " - Return the average RMSE across all cross-validation splits.\n",
    "\n",
    "Fill in the missing code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e346fdb-6809-485d-b17c-44fdaafcbd1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def cross_validate_rmse(model, X, y):\n",
    "    '''\n",
    "    Split the X and y data into 5 subsets.\n",
    "    For each subset, \n",
    "        - Fit a model holding out that subset.\n",
    "        - Compute the RMSE (in units dollars, not log(dollars) on that subset (the validation set).\n",
    "    You should be fitting 5 models in total.\n",
    "    Return the average RMSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: An sklearn model with fit and predict functions. \n",
    "        X (DataFrame):  DataFrame of training/val data, whose columns are the features to use in model (i.e. that have already been processed through the model pipeline) \n",
    "        y (Series): Series of training/val data whose values are the response/output variable that has been processed through the model pipeline\n",
    "    \n",
    "    Return:\n",
    "        The average validation RMSE for the 5 splits.\n",
    "    '''\n",
    "    # Make a copy of the model to use in this function\n",
    "    model = clone(model)\n",
    "\n",
    "    # Initialize sklearn's KFold object \n",
    "    kf = KFold(n_splits=5)  \n",
    "\n",
    "    # Create a list to store the validation_rmse for each fold\n",
    "    validation_rmse = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "       \n",
    "        # Use the provided train_idx and valid_idx to split the data for each fold:\n",
    "        # Recall, train_idx and valid_idx are purely integer-location based indexing for selection by position.\n",
    "        \n",
    "        split_X_train, split_X_valid = ...\n",
    "        split_Y_train, split_Y_valid = ...\n",
    "\n",
    "        # Fit the model on the training split:\n",
    "        ...\n",
    "        \n",
    "        # Compute the RMSE (in units dollars, not log(dollars)) on the validation split:\n",
    "        \n",
    "        error = ...\n",
    "    \n",
    "\n",
    "        validation_rmse.append(error)\n",
    "        \n",
    "\n",
    "        #Return the average validation rmse across all cross-validation splits.\n",
    "\n",
    "    cv_error = ...\n",
    "              \n",
    "        \n",
    "    return cv_error\n",
    "       \n",
    "    \n",
    "# Create a new model to use for cross validation of m1 \n",
    "linear_model_m1_cv = lm.LinearRegression()\n",
    "\n",
    "\n",
    "# Process the `tr_val_clean` DataFrame using the function `process_data_m1`\n",
    "processed_full_m1 = ...\n",
    "\n",
    "# Split the processed_full_m1 DataFrame into a DataFrame X and a Series y to use in the cross_validation_rmse function.\n",
    "X_full_m1 = ...\n",
    "y_full_m1 = ...\n",
    "\n",
    "# Call the `cross_validate_rmse` function you wrote above to calculate the cross_validation RMSE for model 1:\n",
    "cv_error_m1  = ...\n",
    "\n",
    "# Save the cross validation error for model 1 to compare with other models.\n",
    "cv_error[0] = cv_error_m1\n",
    "\n",
    "print(\"1st Model Cross Validation RMSE: {}\".format(cv_error[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e3e90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bd968-c08f-4047-8862-e63e844ac4d1",
   "metadata": {},
   "source": [
    "## Modeling Step 5: Visualizations\n",
    "\n",
    "## Visualizing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43db7c3-9f02-4fc8-bb7b-dcb3ea49e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.  It creates a visualization of the RMSE for Model 1\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f1232-7341-46da-b417-830801fcb760",
   "metadata": {},
   "source": [
    "Notice that our cross-validation RMSE is pretty high given that it's in the units of dollars and measures our error when predicting sale prices of a house.  We will want to improve this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e71d64-0e3a-466f-b19e-52bb95b185f9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "## Visualizing Residual Plots\n",
    "\n",
    "Another way of understanding a model's performance (and appropriateness) is through a plot of the residuals versus the observations.  We will use the validation data to create these plots.\n",
    "\n",
    "In the cells below, use [`plt.scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) to plot\n",
    "2 side-by-side residual plots:\n",
    "\n",
    " - The first plot should be of the residuals from predicting `Log Sale Price` using the model versus  the **predicted** `Log Sale Price` for the **validation data**. \n",
    " - The second plot should be the residuals from predicting `Log Sale Price` using the model versus the **actual** `Log Sale Price` for the **validation data**. \n",
    "\n",
    "We will keep the residuals in terms of units of log to make it easier to spot trends.\n",
    "\n",
    "With such a large dataset, it is difficult to avoid overplotting entirely. We set the dot size and opacity in the scatter plot to reduce the impact of overplotting as much as possible.\n",
    "\n",
    "## QUESTION 4f:  Complete the code below to plot the residual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae2597-7069-4557-a94d-b5ed7ce2501a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 1 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 1 Val Data: Residuals vs. Log(Sale Price)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f205b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49278b94-33fb-4ee9-a318-2802bdd8609b",
   "metadata": {},
   "source": [
    "**NOTE** Notice in the first plot it appears that the lower part of the plot is cutoff along an angled line - this is due to us filtering the data by only considering \"Pure Market Filter\" = 1, it is not a \"pattern\" in the residuals that we should try to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253a3c9-fe7e-4fb7-a277-b2d8124f5871",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 4g\n",
    "\n",
    "Based on the structure you see in your residual plots, does this model seem like it will correspond to _regressive_, _fair_, or _progressive_ taxation?\n",
    "\n",
    "Assign the string \"regressive\", \"fair\" or \"progressive\" to `q4g` in the cell below accordingly.\n",
    "\n",
    "**Hidden test in Gradescope**:  Since this is a question with only 3 possible answers, the in-notebook test will only check if you have the correct format for your answer, it won't check if your actual answer is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5a607-a56a-4f37-90ac-addd2b91ab40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q4g = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3281d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c96095-05c5-4e19-b29f-031df3d89731",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5:  Adding a New Feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e3895-34e7-47be-9f4b-3cb088d709c9",
   "metadata": {},
   "source": [
    "While our simple model explains some of the variability in price, there is certainly still a lot of room for improvement to be made -- one reason is we have been only utilizing 1 feature (out of a total of 60+) so far! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ef259-d8d1-4199-94ab-a11bf779afaf",
   "metadata": {},
   "source": [
    "### Choosing Candidate Predictors to Add to Model\n",
    "\n",
    "\n",
    "\n",
    "To see if additional variables might be helpful, we can plot the residuals from the fitted model against a variable that is not in the model. If we see patterns, that indicates we might want to include this additional feature or a transformation of it. \n",
    "\n",
    "In Project Part 1, you conducted feature transformation to create several other features related to the Sale Price including `Bedrooms` and `Roof Material`.\n",
    "Let's examine plots of the residuals from Model 1 vs each of these features.\n",
    "\n",
    "We have automatically imported staff implementations of the functions you wrote in Project 1 (these are stored in `feature_func.py`).  You are welcome to copy over your own implementations from Project 1 if you'd prefer. \n",
    "\n",
    "These functions are:\n",
    "\n",
    " - `add_total_bedrooms`, \n",
    " - `find_expensive_neighborhoods`, \n",
    " - `add_in_expensive_neighborhood`,\n",
    " - `ohe_roof_material`,\n",
    " -  `remove_outliers`,  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93845f-1691-4363-8de4-312bf574ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell - it creates the columns of the 2 additional features \n",
    "# we're interested in considering to add to the model \n",
    "# and appends the residual data from Model 1, so we can easily visualize\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "\n",
    "def process_data_candidates(df):\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    data[\"Log Sale Price\"] = np.log(data[\"Sale Price\"])\n",
    "    \n",
    "    # Create Log Building Square Feet column\n",
    "    data[\"Log Building Square Feet\"] = np.log(data[\"Building Square Feet\"])\n",
    "    \n",
    "    \n",
    "    # Create Bedrooms\n",
    "    data = add_total_bedrooms(data)\n",
    "     \n",
    "   \n",
    "    # Update Roof Material feature with names\n",
    "    data = substitute_roof_material(data)\n",
    "\n",
    "    \n",
    "    # Select columns for comparing residuals\n",
    "    data = data[['Log Building Square Feet',  'Roof Material', 'Bedrooms', 'Log Sale Price']]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#Since our residuals are using the validation data, we will just examine these new features on the validation dataset\n",
    "    \n",
    "valid_comp = process_data_candidates(val)\n",
    "    \n",
    "valid_comp = valid_comp.assign(M1residuals_log=y_valid_m1 - y_predict_valid_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f206997-8542-4dc5-96ec-7c0019a96791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to compare residuals with Bedrooms\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "px.box(valid_comp, x='Bedrooms', y='M1residuals_log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36fe62-a50e-4b42-888e-84d2c72de36c",
   "metadata": {},
   "source": [
    "Notice, with the exception of the outlier (the properties with 10 bedrooms), the medians of each boxplot align pretty close to 0 on the y-axis (meaning there is no major trend in prediction errors by Number of Bedrooms).\n",
    "\n",
    "This means we do NOT expect adding the features Bedrooms will help improve our original model. \n",
    "\n",
    "What about Roof Material?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707f716-7575-43c3-be93-75b83a9da987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to compare residuals vs Roof Material\n",
    "\n",
    "px.box(valid_comp, x='Roof Material', y='M1residuals_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fb07f-ce50-416b-af97-3e9494295516",
   "metadata": {},
   "source": [
    "The plot above shows us that the distribution of errors appears to change slightly based on Roof Material. Ideally, the median of each  box plot lines up with 0 on the y-axis (meaning there was no difference in prediction by Roof Material type). Instead, we see some variation from 0 for all except Shingle/Asphalt.   These patterns suggest that we may want to try including Roof Material in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b61b64-5a52-447f-b088-be206be00ff6",
   "metadata": {},
   "source": [
    "## Question 5a:  Model 2\n",
    "\n",
    "Let's add `Roof Material` as a predictor in our model.  We will transform the column to be in terms of the Room Material names (like you did in Project Part 1, instead of the number codes).   In other words, let's consider a model of the form:\n",
    "\n",
    "Model 2: \n",
    "$$\\text{Log Sale Price} =  \\theta_1(\\text{Log Building Square Feet})  +\\theta_2 (\\text{Shingle/Asphalt}) $$\n",
    "\n",
    "$$+ \\theta_3 (\\text{Tar\\&Gravel}) + \\theta_4  (\\text{Tile})+ \\theta_5 (\\text{Shake})+  \\theta_6(\\text{Other})+\\theta_7(\\text{Slate})$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Note:** This will require one-hot-encoding Roof Material.  Notice since we're one-hot-encoding we don't need to include an extra intercept term in the model. \n",
    "\n",
    "In the cells below fill in the code to create a function `process_data_m2` to apply feature transformations to the features we'll use in Model 2\n",
    "\n",
    "#### Modeling Step 1:  Process the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b2eb-e965-4a9f-a7bc-6db9a4229ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "# Hint: You can either use your implementation of the \n",
    "# One Hot Encoding Function from Project Part 1, or use the staff's implementation \n",
    "# imported from the feature_func.py file:\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "...\n",
    "# Optional:  Define any helper functions you need for one-hot encoding above this line\n",
    "\n",
    "\n",
    "def process_data_m2(df):\n",
    "\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame of cleaned data and performs feature engineering to use for Model 2.\n",
    "    Includes creating a Log Sale Price column, a Log Building Square Feet Column, \n",
    "    and one-hot encoding roof materials to use in the model.\n",
    "    Once you have one-hot encoded the roof materials, you should drop the \n",
    "    original (not encoded) column `Roof Material` as it will not be used in the model.\n",
    "\n",
    "    Outputs a DataFrame with only the features and response/output used in model 2.  \n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    data = df.copy()\n",
    "\n",
    "    ...\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "\n",
    "# Use the same `tr` and `val` datasets from Question 3 (otherwise the validation errors aren't comparable), \n",
    "# Don't resplit the data.  \n",
    "\n",
    "# Process the data for Model 2\n",
    "processed_train_m2 = ...\n",
    "\n",
    "processed_val_m2 = ...\n",
    "\n",
    "\n",
    "# Create X (dataframe) and Y (series) to use in the model\n",
    "X_train_m2 = ...\n",
    "y_train_m2 = ...\n",
    "\n",
    "X_valid_m2 = ...\n",
    "y_valid_m2 = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m2.head())\n",
    "display(y_train_m2.head())\n",
    "\n",
    "display(X_valid_m2.head())\n",
    "display(y_valid_m2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c580553",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc349d50-1ff2-4a48-a471-3bde13ee930b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Modeling STEP 2:  Create a Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80365b-df1e-4ddf-92e7-a65d3262af58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create and Fit a Multiple Linear Regression Model\n",
    "\n",
    "...\n",
    "# your code above this line to create and fit regression model for Model 2\n",
    "\n",
    "y_predict_train_m2 = ...\n",
    "\n",
    "y_predict_valid_m2 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3c007",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5aii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737edbf2-d4f8-48eb-add0-e2866f22df7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### MODELING STEP 3:  Evaluate the RMSE for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b807f6-2f74-4081-bf25-639a8b7db34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "\n",
    "# Training and test errors for the model (in its original values of dollars, not log)\n",
    "training_error[1] = ...\n",
    "validation_error[1] = ...\n",
    "\n",
    "\n",
    "\n",
    "print(\"2nd Model \\nTraining RMSE: $ {}\\nValidation RMSE: $ {}\\n\".format(training_error[1], validation_error[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe09a258",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5aiii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4a784-cf06-4bac-8fb7-13b401770cd4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### MODELING STEP 4:  Conduct 5-fold cross validation for model and output CV RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a994ab-22b7-45e2-bfec-9f02b879fe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 4:  Conduct 5-fold cross validation for model and output CV RMSE\n",
    "\n",
    "# Create a new model to use for cross validation of m2 \n",
    "linear_model_m2_cv = lm.LinearRegression()\n",
    "\n",
    "\n",
    "# Process the entire cleaned training_val dataset using the m2 pipeline\n",
    "processed_full_m2 = ...\n",
    "\n",
    "# Split the processed_full_m2 Dataset into X and Y to use in models.\n",
    "X_full_m2 = ...\n",
    "y_full_m2 = ...\n",
    "\n",
    "\n",
    "# Run cross_validate_rmse function:\n",
    "cv_error_m2  = ...\n",
    "\n",
    "# Save the cross validation error for model 1 in our list to compare different models:\n",
    "\n",
    "cv_error[1] = cv_error_m2\n",
    "\n",
    "print(\"2nd Model Cross Validation RMSE: {}\".format(cv_error[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92633b98",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5aiv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf0915-e1b4-40f5-9752-a0694caa74ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### MODELING STEP 5:  Just run this cell to Plot bar graph comparing RMSEs of Model 2 and Model 1 and side-by-side residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eab6eb-295a-4572-9f33-141a2fae6a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5:  Just run this cell to Plot bar graph comparing RMSEs of Model 2 and Model 1 and side-by-side residuals\n",
    "\n",
    "model_names[1] = \"M2: log(bsqft)+Roof\"\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e80df0-626c-4319-af2c-7c73baac4e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5 cont'd:  Plot 2 side-by-side residual plots (similar to Question 3, for validation data)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 2 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 2 Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668530fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5av\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904d87a-9fa9-4e6f-8499-d0d509f7a7a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Question 5b\n",
    "\n",
    "\n",
    "We only see a slight decrease in the RMSE with this 2nd model, and our residuals look nearly the same as Model 1, even though the boxplots of Roof Material vs the residuals of Model 1 had indicated it might be a useful feature to add to the model.  \n",
    "\n",
    "What went wrong?\n",
    "  \n",
    "Although there was variation in the boxplots we didn't check the number of data points actually in each different Roof Material Category, which will affect how useful the feature will be in reducing the RMSE.  \n",
    "\n",
    "To see this, group the `valid_comp` data by Roof Material Type and calculate the proportion of data in each category.  \n",
    "\n",
    "Set the variable `val_data_prop_roof_type` equal to a `series` with indices given by Roof Material Name and values that are the proportion of validation data of that roof type.\n",
    "\n",
    "(for example `val_data_prop_roof_type[\"Shingle/Asphalt\"]` should return a float that is the proportion of data points with that type of roof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdf85-e7e9-4e43-9a70-ebcf615d04fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data_prop_roof_type = ...\n",
    "\n",
    "val_data_prop_roof_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cb90e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffac3b4-c884-453e-bcba-aa7c2a8e3585",
   "metadata": {},
   "source": [
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6:  Improving the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a219dad-a05c-4b11-9275-725eb0011a35",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6a:  Choose an additional feature\n",
    "\n",
    "It's your turn to choose another feature to add to the model.  Choose one new **quantitative** (not qualitative) feature and create Model 3 incorporating this feature (along with the features we've already chosen in Model 2).    Try to choose a feature that will have a large impact on reducing the RMSE and/or will improve your residual plots.  This can be a raw feature available in the dataset, or a transformation of one of the features in the dataset, or a new feature that you create from the dataset (see Project 1 for ideas).    \n",
    "\n",
    "Note:  There is not one single right answer as to which feature to add, however **to receive credit on this question you should make sure the feature decreases the Cross Validation RMSE compared to Model 2 (i.e. we want to improve the model, not make it worse!)** \n",
    "\n",
    "\n",
    "In the cell below, explain what additional feature you have chosen and why.  Justify your reasoning.  There are optional code cells provided below for you to use when exploring the dataset to determine which feature to add. \n",
    "\n",
    "This problem will be graded based on your reasoning and explanation of the feature you choose, and then on your implementation of incorporating the feature.   \n",
    "\n",
    "**NOTE** Please don't add additional coding cells below or the Autograder will have issues.  You do not need to use all the coding cells provided.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb888340-fe11-4098-b545-4efc968553eb",
   "metadata": {},
   "source": [
    "### Question 6a Answer Cell:   \n",
    "In this cell, explain what **QUANTITATIVE** feature  you chose and why (for this problem you will **NOT** receive credit if you choose a feature whose conceptual variable type is Qualitative, so double check before continuing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04c04e-a63d-42fd-96a6-6ebe7ac2e5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Show work in this cell exploring data to determine which feature to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50a27c-3828-4104-bbe1-ba14296898f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b240-5966-469d-9969-a39e72aa3a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc573a-ec39-4b72-8e6d-ee0c16a57660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0dc5b-e5f6-4bcf-8a74-0e31fc4407e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6b:  Create Model 3\n",
    "\n",
    "In the cells below fill in the code to create and analyze Model 3 (follow the Modeling steps outlined above).\n",
    "\n",
    "PLEASE DO NOT ADD ANY ADDITIONAL CELLS IN THIS PROBLEM OR IT MIGHT MAKE THE AUTOGRADER FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157b653-4fcc-4aef-8f00-6929ecda2c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "# Hint: You can either use your implementation of the One Hot Encoding Function \n",
    "#from Project Part 1, or use the staff's implementation\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "...\n",
    "# Optional:  Define any helper functions you need for one-hot encoding above this line\n",
    "\n",
    "\n",
    "def process_data_m3(df):\n",
    "    \n",
    "    data = df.copy()\n",
    "        \n",
    "    ...\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "\n",
    "# Process the data for Model 3 (using the same tr and val datatsets we created in Question 3) \n",
    "processed_train_m3 = process_data_m3(tr) \n",
    "\n",
    "processed_val_m3 = process_data_m3(val) \n",
    "\n",
    "# Create X (Dataframe) and y (series) to use to train the model\n",
    "X_train_m3 = ...\n",
    "y_train_m3 = ...\n",
    "\n",
    "X_valid_m3 = ...\n",
    "y_valid_m3 = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m3.head())\n",
    "display(y_train_m3.head())\n",
    "\n",
    "display(X_valid_m3.head())\n",
    "display(y_valid_m3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d15190-7427-4b88-b522-97b7506eca0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create and Fit a Multiple Linear Regression Model\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "# your code above this line to create and fit regression model for Model 3\n",
    "\n",
    "y_predict_train_m3 = ...\n",
    "\n",
    "y_predict_valid_m3 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e82bbe-75b6-49f9-af01-f6bab090ab53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "\n",
    "# Training and validation errors for the model (in units dollars, not log(dollars))\n",
    "\n",
    "training_error[2] = ...\n",
    "validation_error[2] = ...\n",
    "\n",
    "\n",
    "(print(\"3rd Model \\nTraining RMSE: $ {}\\nValidation RMSE: {}\\n\"\n",
    "       .format(training_error[2], validation_error[2]))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336411c9-e7a6-4f1c-a5af-cb5f467067ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# MODELING STEP 4:  Conduct 5-fold cross validation for model and output RMSE\n",
    "\n",
    "linear_model_m3_cv = lm.LinearRegression()\n",
    "\n",
    "\n",
    "# Process the entire cleaned training_val dataset using the m3 pipeline\n",
    "processed_full_m3 = ...\n",
    "\n",
    "# Split the processed_full_m3 Dataset into X and y to use in models.\n",
    "X_full_m3 = ...\n",
    "y_full_m3 = ...\n",
    "\n",
    "\n",
    "# Run cross_validate_rmse function:\n",
    "cv_error_m3  = ...\n",
    "\n",
    "# Save the cross validation error for model 3 in our list to compare different models:\n",
    "\n",
    "cv_error[2] = cv_error_m3\n",
    "\n",
    "print(\"3rd Model Cross Validation RMSE: {}\".format(cv_error[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d987ff-6de0-48ec-a267-9465004b0691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5:  Add a name for your 3rd model describing the features \n",
    "#and run this cell to Plot bar graph all 3 models\n",
    "\n",
    "model_names[2] = ...\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626111cb-3c63-45f8-86c0-3fd5d9408f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5 cont'd:  Plot 2 side-by-side residual plots \n",
    "#(similar to Question 3, for validation data)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 3 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 3 Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1abfdc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ee1e6-5e76-4011-8c3c-ac0a8d010a63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6c\n",
    "\n",
    " - 6ci).  Comment on your RMSE and residual plots from Model 3 compared to the first 2 models.  \n",
    "\n",
    " - 6cii).  Are the residuals of your model still showing a trend that overestimates lower priced houses and underestimates higher priced houses?   If so, how could you try to address this in the next round of modeling?\n",
    "\n",
    " - 6ciii).  If you had more time to improve your model, what would your next steps be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922f4c7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87532b31-694c-4c46-b34c-9a56a1fc2d8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 7: Evaluating the Model in Context\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf2a8f-4fae-4b9d-9e93-55629433d2b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "---\n",
    "## Question 7a\n",
    "\n",
    "When evaluating your model, we used RMSE. In the context of estimating the value of houses, what does the residual mean for an individual homeowner? How does it affect them in terms of property taxes? Discuss the cases where residual is positive and negative separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e04e7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be950ff7-6580-4425-80f6-0b10d9337cbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In the case of the Cook County Assessorâ€™s Office, Chief Data Officer Rob Ross states that fair property tax rates are contingent on whether property values are assessed accurately - that theyâ€™re valued at what theyâ€™re worth, relative to properties with similar characteristics. This implies that having a more accurate model results in fairer assessments. The goal of the property assessment process for the CCAO, then, is to be as accurate as possible. \n",
    "\n",
    "When the use of algorithms and statistical modeling has real-world consequences, we often refer to the idea of fairness as a measurement of how socially responsible our work is. Fairness is incredibly multifaceted: Is a fair model one that minimizes loss - one that generates accurate results? Is it one that utilizes \"unbiased\" data? Or is fairness a broader goal that takes historical contexts into account?\n",
    "\n",
    "These approaches to fairness are not mutually exclusive. If we look beyond error functions and technical measures of accuracy, we'd not only consider _individual_ cases of fairness, but also what fairness - and justice - means to marginalized communities on a broader scale. We'd ask: What does it mean when homes in predominantly Black and Hispanic communities in Cook County are consistently overvalued, resulting in proportionally higher property taxes? When the white neighborhoods in Cook County are consistently undervalued, resulting in proportionally lower property taxes? \n",
    "\n",
    "Having \"accurate\" predictions doesn't necessarily address larger historical trends and inequities, and fairness in property assessments in taxes works beyond the CCAO's valuation model. Disassociating accurate predictions from a fair system is vital to approaching justice at multiple levels. Take Evanston, IL - a suburb in Cook County - as an example of housing equity beyond just improving a property valuation model: Their City Council members [recently approved reparations for African American residents](https://www.usnews.com/news/health-news/articles/2021-03-23/chicago-suburb-approves-government-reparations-for-black-residents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e730874-69ce-40b1-bfd6-1fa96540b277",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 7b\n",
    "\n",
    "Reflecting back on your exploration in Questions 5 and 6a, in your own words, what makes a model's predictions of property values for tax assessment purposes \"fair\"? \n",
    "\n",
    "This question is open-ended and part of your answer may depend upon your specific model; we are looking for thoughtfulness and engagement with the material, not correctness. \n",
    "\n",
    "**Hint:** Some guiding questions to reflect on as you answer the question above: What is the relationship between RMSE, accuracy, and fairness as you have defined it? Is a model with a low RMSE necessarily accurate? Is a model with a low RMSE necessarily \"fair\"? Is there any difference between your answers to the previous two questions? And if so, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318c2b6",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6307f-43d3-4c1d-b3c4-f847667db4c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Extra Credit:  How Low Can You Go?   Create Your Own Model and Check RMSE on the Test Data\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f1d86-680a-4448-b806-db1ff1869c5e",
   "metadata": {},
   "source": [
    "\n",
    "For **extra credit**, you can create your own model to try to improve the RMSE and residual plots even further. \n",
    "\n",
    "The tables below provide scoring guidelines for the extra credit opportunity in this problem. \n",
    "If your RMSE lies in a particular range, you will receive the number of points associated with that range.\n",
    "\n",
    "\n",
    "\n",
    "### Extra Credit Grading Scheme\n",
    "\n",
    "**Important**: To avoid memory issues we will only be using simple cross validation, not 5-fold cross validation in this extra credit part.  While your Validation RMSE can be checked at any time in this notebook, your Test RMSE can only be checked once by submitting your modelâ€™s predictions to Gradescope. The thresholds are as follows:\n",
    "\n",
    "Extra Credit Points | +10 | +8 | +6  | +4 | + 2\n",
    "--- | --- | --- | --- | --- | ---\n",
    "Validation RMSE | Less than 200k | [200k, 210k) | [210k, 220k) | [220k, 230k)  | [230k, 235k)\n",
    "\n",
    "Extra Credit Points | +10 | +8 | +6  | +4 | + 2\n",
    "--- | --- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 200k | [200k, 210k) | [210k, 220k) | [220k, 230k)| [230k, 235k)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "To receive these points, you need to show your work in the cells below AND complete the EXPLANATION STEP at the end (explaining what you did to create your model).  \n",
    "\n",
    "You ALSO MUST UPLOAD your test prediction .csv to the **\"Project 2 Extra Credit Test Predictions\"** assignment in Gradescope to receive extra credit for your test predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Some notes before you start\n",
    "\n",
    "- **If you are running into memory issues, restart the kernel and only run the cells you need to.**   If needed you can use the commented cell below (question cell) that contains most to all of the imports necessary to successfully complete this portion of the project, so it can be completed independently code-wise from the remainder of the project, and you do not need to rerun the cell at the top of this notebook. The autograder will have more than 4GB of memory, so you will not lose credit as long as your solution to this question is within the total memory (4GB) limits of DataHub. By default, we reset the memory and clear all variables using `%reset -f`. If you want to delete specific variables, you may also use `del` in place of `%reset -f%`. For example, the following code will free up memory from data used for older models: `del tr_val_data, test_data, tr, val, X_train_m1, X_valid_m1, X_train_m2, X_valid_m1`. Our staff solution can be run independently from all other questions, so we encourage you to do the same to make debugging easier.\n",
    "- Tip: Feel free to try using [regularization](https://learningds.org/ch/16/ms_regularization.html) for model selection. \n",
    "- To avoid memory issues, you do not need to include cross validation for this step.  Your score will be based on the Validation Data set RMSE and the Test dataset RMSE.\n",
    "- **Note: If you need the data again after deleting the variables or resetting, you must reload them again.**\n",
    "- You will be predicting `Log Sale Price` on the data stored in `cook_county_contest_test.csv`. We will delog/exponentiate your prediction on Gradescope to compute RMSE and use this to score your model. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e., if one of your `Log Sale Price` predictions is 60, it is too large; $e^{60}$ is too big!)\n",
    "- You MUST remove any additional new cells you add before submitting to Gradescope to avoid any autograder errors. \n",
    "\n",
    "\n",
    "**PLEASE READ THE ABOVE MESSAGE CAREFULLY!**\n",
    "\n",
    "**Hints:** \n",
    "- Some features may have missing values in the test set but not in the training set (especially if you're one-hot-encoding). Make sure `process_data_ec` handles missing values appropriately for each feature!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e590f-5b0c-44f4-8d22-dded2e3b952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose.\n",
    "# You can add additional code cells directly below this if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52563760-3ea3-489d-8b0a-e74990391498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f02e98-a8c5-4580-98d6-1e2509e464ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional cell to try if you're having memory issues (i.e. if kernel keeps dying)\n",
    "\n",
    "\n",
    "# If you're having memory issues, uncomment the lines below to clean up \n",
    "#memory from previous questions and reinitialize Otter!\n",
    "\n",
    "\n",
    "\n",
    "# MAKE SURE TO RECOMMENT THE NEXT 3 LINES OUT BEFORE SUBMITTING!\n",
    "\n",
    "#%reset -f\n",
    "#import otter\n",
    "#grader = otter.Notebook(\"ProjPart2.ipynb\")\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#from pandas.api.types import CategoricalDtype\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn import linear_model as lm\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import zipfile\n",
    "#import os\n",
    "\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "#from ds100_utils import *\n",
    "#from feature_func import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tr_val_data = pd.read_csv(\"data/cook_county_train_val.csv\", index_col='Unnamed: 0')\n",
    "#test_data = pd.read_csv(\"data/cook_county_contest_test.csv\", index_col='Unnamed: 0')\n",
    "\n",
    "# COPY THESE FUNCTIONS FROM ABOVE\n",
    "\n",
    "#def rmse(predicted, actual):\n",
    "\n",
    "\n",
    "#def clean_data(data):\n",
    "    \n",
    "    \n",
    "\n",
    "#tr_val_clean = clean_data(tr_val_data) \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#def train_val_split(data):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## To ensure reproducibility, we will shuffle the data once before running it through the train_val split function\n",
    "#tr_val_data_shuffled = tr_val_data.sample(frac=1, random_state=18)\n",
    "\n",
    "## Clean the data\n",
    "#tr_val_clean = clean_data(tr_val_data_shuffled) \n",
    "\n",
    "## Create the train/val split on the cleaned, shuffled data:\n",
    "#tr, val = train_val_split(tr_val_clean)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bc6a5-98f6-433f-b1d7-cda8fb6330ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Extra Credit Step 1: Creating Your Model\n",
    "Complete the modeling steps (you can skip the cross validation step to save memory) in the cells below.\n",
    "\n",
    "DO NOT ADD ANY EXTRA CELLS BELOW (for this part of the problem)\n",
    "\n",
    "# Please include all of your feature engineering processes \n",
    "    # for the training, validation and test sets.\n",
    "    # dataset_type is a flag to use as follows:\n",
    "    # dataset_type=1  imples the data is the training data\n",
    "    # dataset_type=2 implies the data is the validation data\n",
    "    # dataset_type = 3 imples the data is the test data\n",
    "\n",
    "    #Important Instructions:\n",
    "    # When processing the training data, you CAN drop any rows/data that you deem to be outliers\n",
    "    # When processing the validation data you CANNOT drop any rows\n",
    "    # When processing the test data, you CANNOT drop any rows, and you CANNOT reference \"Sale Price\", as it is not in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f8769-b38c-4d95-b801-77256f524171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "\n",
    "# Hint: You can either use your implementation of the One Hot Encoding Function from \n",
    "#Project Part 1, or use the staff's implementation\n",
    "from feature_func import *\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "# # Optional:  Define any helper functions you need (for example, for one-hot \n",
    "# #encoding, etc) above this line\n",
    "\n",
    "\n",
    "def process_data_ec(df, dataset_type):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    data = df.copy()\n",
    "    \n",
    "...\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Use the same original train and valid datasets from 3a (otherwise the \n",
    "# validation errors aren't comparable).  Don't resplit the data.  \n",
    "    \n",
    "# Process the data \n",
    "processed_train_ec = process_data_ec(tr, dataset_type=1)\n",
    "\n",
    "processed_val_ec = process_data_ec(val, dataset_type=2)\n",
    "\n",
    "\n",
    "X_train_ec = ...\n",
    "y_train_ec = ...\n",
    "\n",
    "X_valid_ec = ...\n",
    "y_valid_ec = ...\n",
    "\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_ec.head())\n",
    "display(y_train_ec.head())\n",
    "\n",
    "display(X_valid_ec.head())\n",
    "display(y_valid_ec.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6976ef-f522-41af-9acf-d242d180d48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this code to make sure you haven't dropped any of the rows in the validation set\n",
    "\n",
    "assert X_valid_ec.shape[0] == 33475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9b7e0-d2c3-47bd-b26b-abfb35bb28ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create a Multiple Linear Regression Model\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "# your code above this line to create regression model \n",
    "\n",
    "y_predict_train_ec = ...\n",
    "\n",
    "y_predict_valid_ec = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628c260-ec41-4465-bd2c-2110a3e9d626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "\n",
    "# Training and test errors for the model \n",
    "#(in its original values before the log transform)\n",
    "\n",
    "training_error_ec = ...\n",
    "validation_error_ec = ...\n",
    "\n",
    "\n",
    "(print(\"Extra Credit \\nTraining RMSE:$ {}\\nValidation RMSE:$ {}\\n\"\n",
    "       .format(training_error_ec, validation_error_ec))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a0943-96b8-4de4-80b8-a1b72d269558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional: Run this cell to visualize\n",
    "\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = [\"Extra Credit Model\"], y = [training_error_ec], name=\"Training RMSE\"),\n",
    "go.Bar(x = [\"Extra Credit Model\"], y = [validation_error_ec], name=\"Validation RMSE\"),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "fig\n",
    "fig.update_yaxes(range=[140000,260000], title=\"RMSE\")\n",
    "# Feel free to update the range as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529960bf-78ba-44b4-b9f2-83674b92cc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5: Plot 2 side-by-side residual plots for validation data\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"EC Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"EC Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f0a63-e962-4af6-b6e2-2776a1e0196c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Extra Credit Step 2:  Explanation (Required for points on model above):\n",
    "\n",
    " - Explain what you did to create your model.  What versions did you try?  What worked and what didn't? \n",
    "\n",
    " - Comment on the RMSE and residual plots from your model.   Are the residuals of your model still showing a trend that overestimates lower priced houses and underestimates higher priced houses?\n",
    "\n",
    "**Write your answers in the text cell below**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15999e8",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5d7fc-f90a-4531-80f9-f1147b91129c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Extra Credit Step 3: Create and Submit Test Set Predictions to Gradescope\n",
    "\n",
    "Now it's time to test your model on the actual test set.  You are only allowed to submit to Gradescope once, so wait until you have the best version of your model.    \n",
    "\n",
    "When you are happy with your model and ready to submit, set the variable `did_ec = True` in the cell below your final prediction code.\n",
    "\n",
    "The test data is in the dataframe `test_data`. \n",
    "\n",
    "Process the test data and run it through your model. Store your predictions from the test_data in the variable `y_test_pred`.  These should be in units Log Sale Price (you do not need to exponentiate them).  \n",
    "\n",
    "Then run the cell provided below to create a .csv file to store your predictions on the test set and submit this .csv to the Gradescope Assignment: **\"Project 2 Extra Credit Test Predictions\"**. \n",
    "Note that **you will not receive credit for the test set predictions (i.e. up to 10 points) unless you submit your.csv to the Gradescope assignment**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6f6d8-872a-43a9-8b84-41e8a9d822f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set this to True if you are attempting the extra credit and submitting predictions to Gradescope\n",
    "did_ec = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8474037-f12b-4b92-aa14-342180ac6942",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Cells to process the test_data and run the model on it.  \n",
    "# You CAN add any additional cells below\n",
    "# Note: Make sure you don't remove any of the rows from the test data set.\n",
    "\n",
    "processed_test_ec = process_data_ec(test_data, dataset_type = 3) \n",
    "\n",
    "\n",
    "y_test_pred = linear_model_ec.predict(processed_test_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62eefc-b626-4e0e-afe7-8363ebeb6688",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98988b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"8c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11c9c5-7edf-4aad-a460-aa0ae4e8e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this file to create the .csv of your predictions for the test set to upload to the assignment in Gradescope labeled Project 2 Extra Credit Test Predictions to have it checked.\n",
    "\n",
    "\n",
    "#Store your predictions for the test set in Y_test_pred \n",
    "#(these should be in units of Log Sale Price)\n",
    "\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": pd.read_csv('data/cook_county_contest_test.csv')['Unnamed: 0'], \n",
    "    \"Value\": y_test_pred,\n",
    "}, columns=['Id', 'Value'])\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print('Created a CSV file:')\n",
    "print('You MUST now upload this CSV file to the Gradescope assignment \"Project 2 Extra Credit Test Predictions\" for scoring.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a76fb8-a6be-4bf7-b81a-6a65b341a21a",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished the Project - Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec082596-e29c-4224-bf42-73fb00ce58ea",
   "metadata": {},
   "source": [
    "If you discussed this assignment with any other students in the class (in a manner that is acceptable as described by the Collaboration policy above) please **include their names** here:\n",
    "\n",
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cb90d-5ca5-4a83-8f95-79caa419daaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Before proceeding any further, **save this notebook.**\n",
    "\n",
    "After running the `grader.export()` cell provided below, **2 files will be created**: a zip file and pdf file.  You can download them using the links provided below OR by finding them in the same folder where this juptyer notebook resides in your JuptyerHub.\n",
    "\n",
    "To receive credit on this assignment, **you must submit BOTH of these files\n",
    "to their respective Gradescope portals:** \n",
    "\n",
    "* **Project Part 2 Autograded**: Submit the zip file that is output by the `grader.export()` cell below to the Autograded assignment in Gradescope.\n",
    "\n",
    "* **Project Part 2 Manually Graded**: Submit your ProjectPart2.PDF to the  Manually Graded assignment in Gradescope.  **YOU MUST SELECT THE PAGES CORRESPONDING TO EACH QUESTION WHEN YOU UPLOAD TO GRADESCOPE.  IF NOT, YOU WILL LOSE POINTS**   Also, **check** that all of your plots **and** all lines of your code are showing up in your PDF before submitting.  If not, you will not receive credit for your plots/code.  \n",
    "\n",
    "* **Extra Credit Submission**:  If you completed the extra credit, to receive credit for the Test Case prediction you must submit your Test Case prediction.csv (generated in the last cell of the extra credit section) to the Gradescope assignment titled \"Project 2 Extra Credit Test Predictions\"\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ba796-b2d2-44e7-94fe-c5f63705d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_latex_checker as slc\n",
    "\n",
    "nb = slc.Nb_checker()\n",
    "nb.run_check(\"ProjPart2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d33c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "AFTER running the cell below, click on <a href='ProjPart2.pdf' download>this link to download the PDF </a> to upload to Gradescope.  There will be a separate link that appears after running the cell below with a link to download the zip file to upload to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4446d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5a330",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py10]",
   "language": "python",
   "name": "conda-env-py10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "8c": {
     "name": "8c",
     "points": [
      0,
      0,
      0,
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not did_ec or y_test_pred.max() < 25\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not did_ec or len(y_test_pred) == 55311\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not did_ec or len(y_predict_valid_ec) == 33475\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not did_ec or y_predict_valid_ec.max() < 25\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not did_ec or round(np.log(val['Sale Price']).sum(), 4) == round(y_valid_ec.sum(), 4)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not did_ec or validation_error_ec == rmse(val['Sale Price'], np.exp(y_predict_valid_ec))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q1c.lower() in ['a', 'b', 'c']\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(count_duplicate_properties) == 'e4da3b7fbbce2345d7772b0674a318d5'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(count_duplicate_rows_to_remove) == 'c51ce410c124a10e0db5e4b97fc2af39'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(max_Sale_Price_filtered) == '333aaeba90d1e6a81f84cead32e1d0af'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(min_Sale_Price_filtered) == 'f5dffc111454b227fbcdf36178dfe6ac'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": [
      0.5,
      0.5,
      0.5,
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(clean_data(tr_val_data).shape[0]) == '009c35b3c4a6bebd5011664b55938b87'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(clean_data(tr_val_data).shape[1]) == '44f683a84163b3523afe57c2e008bc8c'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(clean_data(tr_val_data).loc[:, 'Pure Market Filter'].min()) == 'c4ca4238a0b923820dcc509a6f75849b'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(clean_data(tr_val_data).drop_duplicates().shape[0]) == '009c35b3c4a6bebd5011664b55938b87'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      0,
      0,
      0.5,
      0.5,
      0.5,
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert tr.shape == (133900, 62)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert val.shape == (33475, 62)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all([x in [21302, 19451, 32018, 144262, 197227] for x in list(tr.head(5).index)])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all([x in [17112, 189337, 141725, 9776, 81676] for x in list(val.head(5).index)])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(tr['Sale Price'].mean(), 4)) == '35e7d0d9466122d5734d98438a538831'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(val['Sale Price'].mean(), 4)) == '7fb935913ea9abf050e793d2519cf58d'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(np.mean(X_train_m1['Log Building Square Feet']), 4)) == '100176b725ba2d2415d95b950f4eb7a0'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(np.mean(y_train_m1), 4)) == '57d8186de9bdefd8c8a1d2c5ff0747e4'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(np.mean(X_valid_m1['Log Building Square Feet']), 4)) == 'f9d04bbf52193c599a8cd35b346bc694'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(np.mean(y_valid_m1), 4)) == 'ea597fa91252d2631298adc50c33c4c1'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(y_predict_train_m1.sum(), 4)) == 'f95342b08847163834c7a01e608ee74c'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_predict_valid_m1.sum(), 4)) == 'ff63730127181c964f5ac4c607b2d504'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a = np.array([2.5, 3.4])\n>>> b = np.array([4.1, -2.9])\n>>> assert get_hash(round(rmse(a, b), 4)) == 'aa61658fba433b8f1aca672542a669fb'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> c = np.array([2.5, 3.4, 15, -21.3])\n>>> d = np.array([4.1, -2.9, 17, 24.2])\n>>> assert get_hash(round(rmse(c, d), 4)) == 'efec8eece88cc0295a52b6c660a50a31'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(training_error_log[0], 4)) == '3106b82f9a44367d40e8864cc08db080'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(validation_error_log[0], 4)) == 'c5095d7309712928ec0531d4caa7b444'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(validation_error[0], 4)) == 'd185813466f911339f8c4ef5ea8e0c10'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(training_error[0], 4)) == 'caf5ea3209a75a367b8362c98907b0ec'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4e": {
     "name": "q4e",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(np.mean(X_full_m1.values), 4)) == '622f9b61e67678f3f1b6759b9ec9bfe3'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(np.mean(y_full_m1), 4)) == '317fd6698b0885185ad5a4cfd817cda3'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(cv_error_m1, 4)) == 'c0872f5ae24aaa478f52164232fa613a'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4f": {
     "name": "q4f",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(x_plt1.sum(), 4)) == 'ff63730127181c964f5ac4c607b2d504'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_plt1.sum(), 4)) == '510649bf5aa3dcf1b30b7b0184f5d068'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(x_plt2.sum(), 4)) == 'b796908a3efd5d890639ac8dc7a44ae8'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_plt2.sum(), 4)) == '510649bf5aa3dcf1b30b7b0184f5d068'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4g": {
     "name": "q4g",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q4g.lower() in ['regressive', 'fair', 'progressive']\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5ai": {
     "name": "q5ai",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(X_valid_m2.shape[1]) == '8f14e45fceea167a5a36dedd4bea2543'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(X_train_m2.loc[130829].sum(), 4)) == 'b05b113d6f1bdd756f4f5615bad54906'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_valid_m2[126923], 4)) == '01db7bcf03d5a32b8263635933b2cfa5'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_train_m2[91256], 4)) == '68e93929403400cc606162392bb24d62'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5aii": {
     "name": "q5aii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(y_predict_train_m2.sum(), 2)) == '4a908375e7ca821af550eb6001d101d8'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_predict_valid_m2[4], 4)) == 'c8be9c0dac4bcebd0c1da2a1f3bda4b7'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5aiii": {
     "name": "q5aiii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(training_error[1], 0)) == '2cdf8581678a8c81ebb03317087211d0'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(validation_error[1], 0)) == '366d62d628ff3066554e0dffa2040daf'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5aiv": {
     "name": "q5aiv",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(cv_error[1], 0)) == '932ce6513070f7a2137476280439b520'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5av": {
     "name": "q5av",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(y_plt1.sum(), 0)) == 'a6ba950a4ddd81177949c2aa6ee97db2'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(x_plt2.sum(), 0)) == 'f7328bab8dc02678c21ce1ac6097ca70'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(y_plt2.sum(), 0)) == 'a6ba950a4ddd81177949c2aa6ee97db2'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(val_data_prop_roof_type['Other'], 4)) == '0068d091c9e58937cbc923fc371a4560'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(round(val_data_prop_roof_type['Shingle/Asphalt'], 4)) == 'b27e9b8612bd0466aa247aece295ff64'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_valid_m3.shape[0] == X_valid_m2.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 0 < cv_error[2]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert cv_error[2] < cv_error[1]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
